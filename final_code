{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sinagam Pradeep\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender-Age Train Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8076087639492063270</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2897161552818060146</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>M32-38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4938849341048082022</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245133531816851882</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>M29-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id gender  age   group\n",
       "0 -8076087639492063270      M   35  M32-38\n",
       "1 -2897161552818060146      M   35  M32-38\n",
       "2 -8260683887967679142      M   35  M32-38\n",
       "3 -4938849341048082022      M   30  M29-31\n",
       "4   245133531816851882      M   30  M29-31"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_tr=pd.read_csv('gender_age_train.csv')\n",
    "g_a_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id    0\n",
       "gender       0\n",
       "age          0\n",
       "group        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_tr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_features.html\n",
    "gender_dict=g_a_tr['gender'].value_counts()\n",
    "gender_labels=['Male','Female']\n",
    "male_percentage=(gender_dict['M']*100)//g_a_tr.shape[0]\n",
    "female_percentage=(gender_dict['F']*100)//g_a_tr.shape[0]\n",
    "sizes=[male_percentage,female_percentage]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=gender_labels, autopct='%1.1f%%',\n",
    "         startangle=90)\n",
    "plt.title('Gender Pie Chart')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The number of datpoints for Male gender age groups is more than Female gender age groups so it is an imblanaced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    47904.000000\n",
      "mean        31.052939\n",
      "std          9.454653\n",
      "min          1.000000\n",
      "25%         25.000000\n",
      "50%         29.000000\n",
      "75%         35.000000\n",
      "max         90.000000\n",
      "Name: age, dtype: float64\n",
      "count    26741.000000\n",
      "mean        32.050596\n",
      "std         10.539967\n",
      "min         10.000000\n",
      "25%         25.000000\n",
      "50%         29.000000\n",
      "75%         37.000000\n",
      "max         96.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "g_a_tr_male=g_a_tr[g_a_tr[\"gender\"]==\"M\"]\n",
    "g_a_tr_female=g_a_tr[g_a_tr[\"gender\"]==\"F\"]\n",
    "print(g_a_tr_male[\"age\"].describe())\n",
    "print(g_a_tr_female[\"age\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "1)The Number of Male users is almost double the number of Female.\n",
    "\n",
    "2)25,50 Percentile Age values,mean value for both Male and Female are same.\n",
    "\n",
    "3)In General Female users have more age than Male users in the Data that can be seen from 75 percentile and max age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender Age Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_a_te=pd.read_csv('gender_age_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002079943728939269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1547860181818787117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7374582448058474277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6220210354783429585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5893464122623104785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id\n",
       "0  1002079943728939269\n",
       "1 -1547860181818787117\n",
       "2  7374582448058474277\n",
       "3 -6220210354783429585\n",
       "4 -5893464122623104785"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_te.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_te.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_te.shape[0]==g_a_te.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Brand and Device Model Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_b_d=pd.read_csv('phone_brand_device_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8890648629457979026</td>\n",
       "      <td>小米</td>\n",
       "      <td>红米</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277779817574759137</td>\n",
       "      <td>小米</td>\n",
       "      <td>MI 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5137427614288105724</td>\n",
       "      <td>三星</td>\n",
       "      <td>Galaxy S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3669464369358936369</td>\n",
       "      <td>SUGAR</td>\n",
       "      <td>时尚手机</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5019277647504317457</td>\n",
       "      <td>三星</td>\n",
       "      <td>Galaxy Note 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id phone_brand   device_model\n",
       "0 -8890648629457979026          小米             红米\n",
       "1  1277779817574759137          小米           MI 2\n",
       "2  5137427614288105724          三星      Galaxy S4\n",
       "3  3669464369358936369       SUGAR           时尚手机\n",
       "4 -5019277647504317457          三星  Galaxy Note 2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_b_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phone Brand and Device Model are written in chinese and need to be translated to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_brand_english = {\n",
    "    \"三星\": \"samsung\",\n",
    "    \"天语\": \"Ktouch\",\n",
    "    \"海信\": \"hisense\",\n",
    "    \"联想\": \"lenovo\",\n",
    "    \"欧比\": \"obi\",\n",
    "    \"爱派尔\": \"ipair\",\n",
    "    \"努比亚\": \"nubia\",\n",
    "    \"优米\": \"youmi\",\n",
    "    \"朵唯\": \"dowe\",\n",
    "    \"黑米\": \"heymi\",\n",
    "    \"锤子\": \"hammer\",\n",
    "    \"酷比魔方\": \"koobee\",\n",
    "    \"美图\": \"meitu\",\n",
    "    \"尼比鲁\": \"nibilu\",\n",
    "    \"一加\": \"oneplus\",\n",
    "    \"优购\": \"yougo\",\n",
    "    \"诺基亚\": \"nokia\",\n",
    "    \"糖葫芦\": \"candy\",\n",
    "    \"中国移动\": \"ccmc\",\n",
    "    \"语信\": \"yuxin\",\n",
    "    \"基伍\": \"kiwu\",\n",
    "    \"青橙\": \"greeno\",\n",
    "    \"华硕\": \"asus\",\n",
    "    \"夏新\": \"panosonic\",\n",
    "    \"维图\": \"weitu\",\n",
    "    \"艾优尼\": \"aiyouni\",\n",
    "    \"摩托罗拉\": \"moto\",\n",
    "    \"乡米\": \"xiangmi\",\n",
    "    \"米奇\": \"micky\",\n",
    "    \"大可乐\": \"bigcola\",\n",
    "    \"沃普丰\": \"wpf\",\n",
    "    \"神舟\": \"hasse\",\n",
    "    \"摩乐\": \"mole\",\n",
    "    \"飞秒\": \"fs\",\n",
    "    \"米歌\": \"mige\",\n",
    "    \"富可视\": \"fks\",\n",
    "    \"德赛\": \"desci\",\n",
    "    \"梦米\": \"mengmi\",\n",
    "    \"乐视\": \"lshi\",\n",
    "    \"小杨树\": \"smallt\",\n",
    "    \"纽曼\": \"newman\",\n",
    "    \"邦华\": \"banghua\",\n",
    "    \"E派\": \"epai\",\n",
    "    \"易派\": \"epai\",\n",
    "    \"普耐尔\": \"pner\",\n",
    "    \"欧新\": \"ouxin\",\n",
    "    \"西米\": \"ximi\",\n",
    "    \"海尔\": \"haier\",\n",
    "    \"波导\": \"bodao\",\n",
    "    \"糯米\": \"nuomi\",\n",
    "    \"唯米\": \"weimi\",\n",
    "    \"酷珀\": \"kupo\",\n",
    "    \"谷歌\": \"google\",\n",
    "    \"昂达\": \"ada\",\n",
    "    \"聆韵\": \"lingyun\",\n",
    "    \"小米\": \"Xiaomi\",\n",
    "    \"华为\": \"Huawei\",\n",
    "    \"魅族\": \"Meizu\",\n",
    "    \"中兴\": \"ZTE\",\n",
    "    \"酷派\": \"Coolpad\",\n",
    "    \"金立\": \"Gionee\",\n",
    "    \"SUGAR\": \"SUGAR\",\n",
    "    \"OPPO\": \"OPPO\",\n",
    "    \"vivo\": \"vivo\",\n",
    "    \"HTC\": \"HTC\",\n",
    "    \"LG\": \"LG\",\n",
    "    \"ZUK\": \"ZUK\",\n",
    "    \"TCL\": \"TCL\",\n",
    "    \"LOGO\": \"LOGO\",\n",
    "    \"SUGAR\": \"SUGAR\",\n",
    "    \"Lovme\": \"Lovme\",\n",
    "    \"PPTV\": \"PPTV\",\n",
    "    \"ZOYE\": \"ZOYE\",\n",
    "    \"MIL\": \"MIL\",\n",
    "    \"索尼\" : \"Sony\",\n",
    "    \"欧博信\" : \"Opssom\",\n",
    "    \"奇酷\" : \"Qiku\",\n",
    "    \"酷比\" : \"CUBE\",\n",
    "    \"康佳\" : \"Konka\",\n",
    "    \"亿通\" : \"Yitong\",\n",
    "    \"金星数码\" : \"JXD\",\n",
    "    \"至尊宝\" : \"Monkey King\",\n",
    "    \"百立丰\" : \"Hundred Li Feng\",\n",
    "    \"贝尔丰\" : \"Bifer\",\n",
    "    \"百加\" : \"Bacardi\",\n",
    "    \"诺亚信\" : \"Noain\",\n",
    "    \"广信\" : \"Kingsun\",\n",
    "    \"世纪天元\" : \"Ctyon\",\n",
    "    \"青葱\" : \"Cong\",\n",
    "    \"果米\" : \"Taobao\",\n",
    "    \"斐讯\" : \"Phicomm\",\n",
    "    \"长虹\" : \"Changhong\",\n",
    "    \"欧奇\" : \"Oukimobile\",\n",
    "    \"先锋\" : \"XFPLAY\",\n",
    "    \"台电\" : \"Teclast\",\n",
    "    \"大Q\" : \"Daq\",\n",
    "    \"蓝魔\" : \"Ramos\",\n",
    "    \"奥克斯\" : \"AUX\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translation from Chinese to English\n",
    "p_b_d['phone_brand'] = p_b_d['phone_brand'].apply(lambda x: phone_brand_english[x] if x in phone_brand_english else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8890648629457979026</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>红米</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1277779817574759137</td>\n",
       "      <td>Xiaomi</td>\n",
       "      <td>MI 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5137427614288105724</td>\n",
       "      <td>samsung</td>\n",
       "      <td>Galaxy S4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3669464369358936369</td>\n",
       "      <td>SUGAR</td>\n",
       "      <td>时尚手机</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5019277647504317457</td>\n",
       "      <td>samsung</td>\n",
       "      <td>Galaxy Note 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id phone_brand   device_model\n",
       "0 -8890648629457979026      Xiaomi             红米\n",
       "1  1277779817574759137      Xiaomi           MI 2\n",
       "2  5137427614288105724     samsung      Galaxy S4\n",
       "3  3669464369358936369       SUGAR           时尚手机\n",
       "4 -5019277647504317457     samsung  Galaxy Note 2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_b_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for duplicates\n",
    "p_b_d.shape[0]==p_b_d[\"device_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique devices in p_b_d is 186716\n",
      "Number of duplicates in p_b_d is 529\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Unique devices in p_b_d is {}\".format(p_b_d[\"device_id\"].nunique()))\n",
    "print(\"Number of duplicates in p_b_d is {}\".format(len(p_b_d)-(p_b_d[\"device_id\"].nunique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 529 duplicate devices in phone Data which need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicates from phone data\n",
    "p_b_d=p_b_d.drop_duplicates(subset=\"device_id\",keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_brand=dict(p_b_d['phone_brand'].value_counts())\n",
    "brand_names = [k for k in sorted(phone_brand, key=phone_brand.get, reverse=True)]\n",
    "#Taking Top 10 keys with highest values \n",
    "top_brand_names=brand_names[:10]\n",
    "top_brand_values=[phone_brand.get(k) for k in top_brand_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "indices=np.arange(len(top_brand_names))\n",
    "top_brand_values=np.array(top_brand_values)\n",
    "percent=(top_brand_values/len(p_b_d))*100\n",
    "plt.bar(indices,percent)\n",
    "plt.xlabel('Phone Brands')\n",
    "plt.ylabel('Percentage of each phone brand')\n",
    "plt.title('Percentages of top 10 Phone Brands')\n",
    "plt.xticks(indices,top_brand_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Xiaomi, Samsung, Huawei are the top 3 Phone Brands by Talking Data customers which have a combined user Base of almost 60% of the total users and the other 127 Phone Brands(as total unique phone brands is 130) have a combined user Base of only 40% of the total users. It is Clearly observable that Xiaomi, Samsung and Huawei dominate the other brands in china."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Categories Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_c=pd.read_csv('label_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>game-game type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>game-Game themes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>game-Art Style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>game-Leisure time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_id           category\n",
       "0         1                NaN\n",
       "1         2     game-game type\n",
       "2         3   game-Game themes\n",
       "3         4     game-Art Style\n",
       "4         5  game-Leisure time"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Events Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e=pd.read_csv('events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>device_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>29182687948017175</td>\n",
       "      <td>2016-05-01 00:55:25</td>\n",
       "      <td>121.38</td>\n",
       "      <td>31.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-6401643145415154744</td>\n",
       "      <td>2016-05-01 00:54:12</td>\n",
       "      <td>103.65</td>\n",
       "      <td>30.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-4833982096941402721</td>\n",
       "      <td>2016-05-01 00:08:05</td>\n",
       "      <td>106.60</td>\n",
       "      <td>29.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-6815121365017318426</td>\n",
       "      <td>2016-05-01 00:06:40</td>\n",
       "      <td>104.27</td>\n",
       "      <td>23.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-5373797595892518570</td>\n",
       "      <td>2016-05-01 00:07:18</td>\n",
       "      <td>115.88</td>\n",
       "      <td>28.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id            device_id            timestamp  longitude  latitude\n",
       "0         1    29182687948017175  2016-05-01 00:55:25     121.38     31.24\n",
       "1         2 -6401643145415154744  2016-05-01 00:54:12     103.65     30.97\n",
       "2         3 -4833982096941402721  2016-05-01 00:08:05     106.60     29.70\n",
       "3         4 -6815121365017318426  2016-05-01 00:06:40     104.27     23.28\n",
       "4         5 -5373797595892518570  2016-05-01 00:07:18     115.88     28.66"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Devices:  60865\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Unique Devices: \",(e[\"device_id\"].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event Start:  2016-04-30 23:52:24\n",
      "Event End:  2016-05-08 00:00:08\n"
     ]
    }
   ],
   "source": [
    "# Event Start and End time across the whole Data\n",
    "event_times=e['timestamp'].values\n",
    "print(\"Event Start: \",np.min(event_times))\n",
    "print(\"Event End: \",np.max(event_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "The Events Data provided is for a period of 8 Days Starting from 30th April 2016 mid-night to starting of 8th May 2016 12 AM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of train dataset that have events is 31.22647196731194\n",
      "percentage of train dataset that does not have events is 68.77352803268806\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_a_tr_events=pd.merge(g_a_tr,e,on=\"device_id\",how=\"inner\")\n",
    "event_percentage=(g_a_tr_events[\"device_id\"].nunique()/g_a_tr[\"device_id\"].nunique())*100\n",
    "print(\"percentage of train dataset that have events is {}\".format(event_percentage))\n",
    "print(\"percentage of train dataset that does not have events is {}\".format(100-event_percentage))\n",
    "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.in1d.html\n",
    "event_labels=['HAS EVENTS','DOES NOT HAVE EVENTS']\n",
    "sizes=[event_percentage,100-event_percentage]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=event_labels, autopct='%1.1f%%',\n",
    "         startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title('percentage of presence and absence of events in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of test dataset that have events is 31.403306832275966\n",
      "percentage of test dataset that does not have events is 68.59669316772403\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_a_te_events=pd.merge(g_a_te,e,on=\"device_id\",how=\"inner\")\n",
    "event_percentage=(g_a_te_events[\"device_id\"].nunique()/g_a_te[\"device_id\"].nunique())*100\n",
    "print(\"percentage of test dataset that have events is {}\".format(event_percentage))\n",
    "print(\"percentage of test dataset that does not have events is {}\".format(100-event_percentage))\n",
    "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.in1d.html\n",
    "event_labels=['HAS EVENTS','DOES NOT HAVE EVENTS']\n",
    "sizes=[event_percentage,100-event_percentage]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=event_labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title('percentage of presence and absence of events in testing data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "1. Both Train and Test Data have same percentage of devices with Events ~31%\n",
    "2. Both Train and Test Data have same percentage of devices without Events as well ~69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**App Labels Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_l=pd.read_csv('app_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7324884708820027918</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4494216993218550286</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8694625920731541625</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id  label_id\n",
       "0  7324884708820027918       251\n",
       "1 -4494216993218550286       251\n",
       "2  6058196446775239644       406\n",
       "3  6058196446775239644       407\n",
       "4  8694625920731541625       406"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id      113211\n",
       "label_id       507\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_l.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "Number of Unique app labels is 507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_l_c=pd.merge(a_l,l_c,on='label_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7324884708820027918</td>\n",
       "      <td>251</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4494216993218550286</td>\n",
       "      <td>251</td>\n",
       "      <td>Finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>406</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6058196446775239644</td>\n",
       "      <td>407</td>\n",
       "      <td>DS_P2P net loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8694625920731541625</td>\n",
       "      <td>406</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                app_id  label_id         category\n",
       "0  7324884708820027918       251          Finance\n",
       "1 -4494216993218550286       251          Finance\n",
       "2  6058196446775239644       406          unknown\n",
       "3  6058196446775239644       407  DS_P2P net loan\n",
       "4  8694625920731541625       406          unknown"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_l_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_l_c_names=a_l_c[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Industry tag             56902\n",
       "Custom label             53936\n",
       "Tencent                  49320\n",
       "game                     48707\n",
       "Property Industry 2.0    45697\n",
       "1 free                   19083\n",
       "Services 1               11840\n",
       "Property Industry new     9955\n",
       "Relatives 1               9027\n",
       "Irritation / Fun 1        8831\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 10 most used app categories\n",
    "a_l_c_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**App Events Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_e=pd.read_csv('app_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>app_id</th>\n",
       "      <th>is_installed</th>\n",
       "      <th>is_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5927333115845830913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-5720078949152207372</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1633887856876571208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-653184325010919369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8693964245073640147</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id               app_id  is_installed  is_active\n",
       "0         2  5927333115845830913             1          1\n",
       "1         2 -5720078949152207372             1          0\n",
       "2         2 -1633887856876571208             1          0\n",
       "3         2  -653184325010919369             1          1\n",
       "4         2  8693964245073640147             1          1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id        1488096\n",
       "app_id            19237\n",
       "is_installed          1\n",
       "is_active             2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_e.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1) Number of unique apps is 19237\n",
    "\n",
    "2) Number of unique events is 1488096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_labels=['Is Active','Not Active']\n",
    "is_active=len(a_e[a_e[\"is_active\"]==1])*100/len(a_e)\n",
    "sizes=[is_active,100-is_active]\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=event_labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')\n",
    "plt.title('percentage of apps is active or not active in training data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVATIONS FROM EDA**:\n",
    "\n",
    "1)Only approx 31% of dataset has event details in both training and test datset.\n",
    "\n",
    "2)We need to use Phone Brand and Phone Model Data as features to make a model for Devices without Events to predict testdata points with only these features.\n",
    "\n",
    "3)We can use event related features along with Phone brand and model features for Devices which contain event information.\n",
    "\n",
    "4)Since the training datset contains 12 different groups we can encode them from 0-11 instead of m23 or f30 and so on for our easy convinence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes encoded in to {'F23-': 0, 'F24-26': 1, 'F27-28': 2, 'F29-32': 3, 'F33-42': 4, 'F43+': 5, 'M22-': 6, 'M23-26': 7, 'M27-28': 8, 'M29-31': 9, 'M32-38': 10, 'M39+': 11}\n"
     ]
    }
   ],
   "source": [
    "encoder=LabelEncoder()\n",
    "class_encode=encoder.fit_transform(g_a_tr['group'])\n",
    "#how classess are encoded i.e which number correponds to which class\n",
    "classes= list(encoder.classes_)\n",
    "classes_Encoded = list(encoder.transform(encoder.classes_))\n",
    "print(\"classes encoded in to {}\".format(dict(list(zip(classes,classes_Encoded)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_a_tr[\"class\"]=class_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_a_tr.drop(['age','gender','group'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    51336\n",
       "True     23309\n",
       "Name: events, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_events=np.in1d(g_a_tr[\"device_id\"].values,e[\"device_id\"].values)\n",
    "#creating a events column in both train datset\n",
    "g_a_tr[\"events\"]=ques_events\n",
    "g_a_tr[\"events\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    76877\n",
       "True     35194\n",
       "Name: events, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_events=np.in1d(g_a_te[\"device_id\"].values,e[\"device_id\"].values)\n",
    "#creating a events column in both test datset\n",
    "g_a_te[\"events\"]=ques_events\n",
    "g_a_te[\"events\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>class</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8076087639492063270</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2897161552818060146</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8260683887967679142</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4938849341048082022</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>245133531816851882</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  class  events\n",
       "0 -8076087639492063270     10   False\n",
       "1 -2897161552818060146     10   False\n",
       "2 -8260683887967679142     10    True\n",
       "3 -4938849341048082022      9   False\n",
       "4   245133531816851882      9   False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002079943728939269</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1547860181818787117</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7374582448058474277</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6220210354783429585</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5893464122623104785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             device_id  events\n",
       "0  1002079943728939269    True\n",
       "1 -1547860181818787117    True\n",
       "2  7374582448058474277    True\n",
       "3 -6220210354783429585    True\n",
       "4 -5893464122623104785   False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_a_te.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataset contains both datapoints with and without events we divide them in to 2 datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events=g_a_tr[g_a_tr[\"events\"]==True]\n",
    "train_no_events=g_a_tr[g_a_tr[\"events\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_events=g_a_te[g_a_te[\"events\"]==True]\n",
    "test_no_events=g_a_te[g_a_te[\"events\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events.drop(['events'],axis=1,inplace=True)\n",
    "test_events.drop(['events'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_events.drop(['events'],axis=1,inplace=True)\n",
    "test_no_events.drop(['events'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting device_id as index\n",
    "train_events=train_events.set_index('device_id')\n",
    "train_no_events=train_no_events.set_index('device_id')\n",
    "test_events=test_events.set_index('device_id')\n",
    "test_no_events=test_no_events.set_index('device_id')\n",
    "g_a_te=g_a_te.set_index(\"device_id\")\n",
    "g_a_tr=g_a_tr.set_index(\"device_id\")\n",
    "e=e.set_index('event_id')\n",
    "p_b_d=p_b_d.set_index(\"device_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_e[\"is_active\"]=(a_e[\"is_active\"]).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping is_installed siince it contains only single unique values in the column so, it's of no use\n",
    "a_e=a_e.drop([\"is_installed\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create coloumns trainrow, testrow in Train and Test Data to indicate which row a particular device belongs to and this will be useful in our One-hot encoded Sparse Matrix Creation, in which we will specify row number in the sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_a_tr['trainrow']=np.arange(g_a_tr.shape[0])\n",
    "train_events['trainrow']=np.arange(train_events.shape[0])\n",
    "g_a_te['testrow']=np.arange(g_a_te.shape[0])\n",
    "test_events['testrow']=np.arange(test_events.shape[0])\n",
    "train_no_events['trainrow']=np.arange(train_no_events.shape[0])\n",
    "test_no_events['testrow']=np.arange(test_no_events.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have 2 ways in which Phone Model is used:\n",
    "1. Concatinating Phone Brand + Model to create Unique combinations which will be used for Data Containing Events\n",
    "2. Use the Phone Model as it is without concatinating with Phone Brand for Devices with No Events Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_model = p_b_d['phone_brand'].str.cat(p_b_d['device_model'])\n",
    "encoder=LabelEncoder().fit(concat_model)\n",
    "p_b_d['model_brand']=encoder.transform(concat_model)\n",
    "n_events_models=len(encoder.classes_)\n",
    "model_encode=LabelEncoder().fit(p_b_d['device_model'])\n",
    "p_b_d['device_model']=model_encode.transform(p_b_d['device_model'])\n",
    "n_models=len(model_encode.classes_)\n",
    "model_encode=LabelEncoder().fit(p_b_d['phone_brand'])\n",
    "p_b_d['phone_brand']=model_encode.transform(p_b_d['phone_brand'])\n",
    "n_brands=len(model_encode.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "test_events[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "test_events[\"device_model\"]=p_b_d[\"model_brand\"]\n",
    "train_events[\"device_model\"]=p_b_d[\"model_brand\"]\n",
    "\n",
    "train_no_events[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "test_no_events[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "train_no_events[\"device_model\"]=p_b_d[\"device_model\"]\n",
    "test_no_events[\"device_model\"]=p_b_d[\"device_model\"]\n",
    "\n",
    "g_a_tr[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "g_a_te[\"phone_brand\"]=p_b_d[\"phone_brand\"]\n",
    "g_a_tr[\"device_model\"]=p_b_d[\"device_model\"]\n",
    "g_a_te[\"device_model\"]=p_b_d[\"device_model\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag Of Apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach Refererd from: https://www.kaggle.com/dvasyukova/a-linear-model-on-apps-and-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Each device we want to know which all apps were installed in the device. So we will first encode All the App Ids as integers from 0 to number of unique apps - 1. To get the Apps which are installed in a device denoted by device_id, we merge device_id column from events table to app_events group the resulting dataframe by device_id and app and aggregate. we then Merge in the trainrow, testrow  columns to know at which row to put each device in the features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_encoder = LabelEncoder().fit(a_e['app_id'])\n",
    "a_e['app'] = app_encoder.transform(a_e['app_id'])\n",
    "n_apps = len(app_encoder.classes_)# number of unique apps it will be used in creating One-Hot Encoding of Apps \n",
    "apps_on_devices = (a_e.merge(e[['device_id']], how='left',left_on='event_id',right_index=True)\n",
    "                       .groupby(['device_id','app'])['app'].agg(['size'])\n",
    "                       .merge(train_events[['trainrow']], how='left', left_index=True, right_index=True)#merges by index which is device_id\n",
    "                       .merge(test_events[['testrow']], how='left', left_index=True, right_index=True)#merges by index which is device_id\n",
    "                       .reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bag of Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "App Labels are also created in a similar approach by merging with apps_on_devices dataframe and grouping by labels and then merging it with trainrow, testrow to know at which row to put each device in the feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_l = a_l.loc[a_l['app_id'].isin(a_e['app_id'].unique())]\n",
    "a_l['app'] = app_encoder.transform(a_l['app_id'])\n",
    "labelencoder = LabelEncoder().fit(a_l['label_id'])\n",
    "a_l['label'] = labelencoder.transform(a_l['label_id'])\n",
    "n_labels = len(labelencoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_on_devices = (apps_on_devices[['device_id','app']]\n",
    "                .merge(a_l[['app','label']])\n",
    "                .groupby(['device_id','label'])['app'].agg(['size'])\n",
    "                .merge(train_events[['trainrow']], how='left', left_index=True, right_index=True)#merges by index which is device_id\n",
    "                .merge(test_events[['testrow']], how='left', left_index=True, right_index=True)#merges by index which is device_id\n",
    "                .reset_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event Day and Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Hours from Events Time Stamp\n",
    "e['hour'] = e['timestamp'].map(lambda x:pd.to_datetime(x).hour)\n",
    "e['hourbin'] = [1 if ((x>=1)&(x<=6)) else 2 if ((x>=7)&(x<=12)) else 3 if ((x>=13)&(x<=18)) else 4 for x in e['hour']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping hours by device_id, and concatinating all the hours which occur for a particular device_id and forming a string of all the hours for that device.Appending a '0' string before integers as TFidf or Count Vectorizer strangely don't count single digit numbers as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id\n",
       "-9222956879900151005    011 012 015 012 015 021 015 015 021 07 012 015...\n",
       "-9222661944218806987                       021 019 022 018 018 018 00 018\n",
       "-9222399302879214035              011 013 023 021 013 023 010 013 023 013\n",
       "-9221825537663503111    07 07 07 08 013 07 06 07 07 08 013 08 013 010 ...\n",
       "-9221767098072603291                         05 015 014 012 018 05 013 07\n",
       "Name: hour, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hour_events = e.groupby(\"device_id\")[\"hour\"].apply(lambda x: \" \".join('0'+str(s) for s in x))\n",
    "hour_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id\n",
       "-9222956879900151005    02 02 03 02 03 04 03 03 04 02 02 03 03 02 02 0...\n",
       "-9222661944218806987                              04 04 04 03 03 03 04 03\n",
       "-9222399302879214035                        02 03 04 04 03 04 02 03 04 03\n",
       "-9221825537663503111    02 02 02 02 03 02 01 02 02 02 03 02 03 02 02 0...\n",
       "-9221767098072603291                              01 03 03 02 03 01 03 02\n",
       "Name: hourbin, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourbin_events = e.groupby(\"device_id\")[\"hourbin\"].apply(lambda x: \" \".join('0'+str(s) for s in x))\n",
    "hourbin_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the columns hours,hour bins in train,test using the above created two variables which are created using group by device_id.\n",
    "train_events['event_hours']=train_events.index.map(hour_events)\n",
    "test_events['event_hours']=test_events.index.map(hour_events)\n",
    "train_events['event_hours_bins']=train_events.index.map(hourbin_events)\n",
    "test_events['event_hours_bins']=test_events.index.map(hourbin_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the day of week from timestamp and labelling it\n",
    "e[\"timestamp\"]=pd.to_datetime(e[\"timestamp\"])\n",
    "days_of_week=e['timestamp'].dt.day_name()\n",
    "e['day']=days_of_week.map({'Sunday':0,'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device_id\n",
       "-9222956879900151005    06 06 06 06 05 05 05 05 05 06 06 05 05 06 06 0...\n",
       "-9222661944218806987                              03 04 01 00 06 05 00 02\n",
       "-9222399302879214035                        03 01 02 05 03 03 03 03 02 01\n",
       "-9221825537663503111    06 06 05 00 04 05 05 05 04 00 04 00 01 01 00 0...\n",
       "-9221767098072603291                              03 00 00 03 04 02 01 03\n",
       "Name: day, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_events = e.groupby(\"device_id\")[\"day\"].apply(lambda x: \" \".join('0'+str(s) for s in x))\n",
    "day_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events['event_day']=train_events.index.map(day_events)\n",
    "test_events['event_day']=test_events.index.map(day_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Events Latitude and Longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the medain of latitude and longitude and mapping it to train,test dataset.\n",
    "latitude_events = e.groupby(\"device_id\")[\"latitude\"].apply(lambda x: np.median([float(s) for s in x]))\n",
    "longitude_events = e.groupby(\"device_id\")[\"longitude\"].apply(lambda x: np.median([float(s) for s in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events['event_median_latitude']=train_events.index.map(latitude_events)\n",
    "train_events['event_median_longitude']=train_events.index.map(longitude_events)\n",
    "test_events['event_median_latitude']=test_events.index.map(latitude_events)\n",
    "test_events['event_median_longitude']=test_events.index.map(longitude_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apps is_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we group the is_active by event_id and create a string of is_active values, we then map these values to event_id in events table. Then we group these is_active labels by device_id and concatinate the values to from a string of is_active features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app_active is grouped using event_id \n",
    "app_active = a_e.groupby(\"event_id\")[\"is_active\"].apply(lambda x: \" \".join(str(s) for s in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_id\n",
       "2     True False False True True True False False Fa...\n",
       "6     True True True True True False True False True...\n",
       "7     False True False False True True False False F...\n",
       "9     False False False False False False False True...\n",
       "16    False False False False False False False True...\n",
       "Name: is_active, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_active.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a column in events using the output of above cell\n",
    "e[\"apps_active\"] = e.index.map(app_active)\n",
    "#mapping the app_active to group by device_id\n",
    "device_map_app_active = e.groupby(\"device_id\")[\"apps_active\"].apply(lambda x: \" \".join(str(s) for s in x if str(s)!='nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_events[\"app_active\"]=train_events.index.map(device_map_app_active)\n",
    "test_events[\"app_active\"]=test_events.index.map(device_map_app_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>trainrow</th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>device_model</th>\n",
       "      <th>event_hours</th>\n",
       "      <th>event_hours_bins</th>\n",
       "      <th>event_day</th>\n",
       "      <th>event_median_latitude</th>\n",
       "      <th>event_median_longitude</th>\n",
       "      <th>app_active</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-8260683887967679142</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>843</td>\n",
       "      <td>014</td>\n",
       "      <td>03</td>\n",
       "      <td>00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False False False False True False True False ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      class  trainrow  phone_brand  device_model event_hours  \\\n",
       "device_id                                                                      \n",
       "-8260683887967679142     10         0           51           843         014   \n",
       "\n",
       "                     event_hours_bins event_day  event_median_latitude  \\\n",
       "device_id                                                                \n",
       "-8260683887967679142               03        00                    0.0   \n",
       "\n",
       "                      event_median_longitude  \\\n",
       "device_id                                      \n",
       "-8260683887967679142                     0.0   \n",
       "\n",
       "                                                             app_active  \n",
       "device_id                                                                \n",
       "-8260683887967679142  False False False False True False True False ...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_events.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_store=train_events.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_store=test_events.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_noevents=train_no_events.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_noevents=test_no_events.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the Processed Events Train Data\n",
    "train_data_store.to_csv('Processed_events_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the Processed Events Test\n",
    "test_data_store.to_csv('Processed_events_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the Processed No Events Train Data\n",
    "train_data_noevents.to_csv('Processed_no_events_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the Processed No Events Test\n",
    "test_data_noevents.to_csv('Processed_no_events_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/8955448/save-load-scipy-sparse-csr-matrix-in-portable-data-format\n",
    "def save_sparse(filename, xmtr):\n",
    "\n",
    "    np.savez(filename,data = xmtr.data ,indices= xmtr.indices,\n",
    "             indptr =xmtr.indptr, shape=xmtr.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/8955448/save-load-scipy-sparse-csr-matrix-in-portable-data-format\n",
    "def load_sparse(filename):\n",
    "    tmp = np.load(filename)\n",
    "    return csr_matrix((tmp['data'], tmp['indices'], tmp['indptr']), shape= tmp['shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We Use 2 Different Sets of Features for Data with Events and Data without Events\n",
    "1. **Data Without Events:** One-hot Encodings of Phone Brand, Phone Model, has Event\n",
    "2. **Data with Events:** One-hots of Apps, Labels, Phone Brand, Phone Model, Event Day, Event Hour, Standardized  Latitude and Longitude values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Devices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoding using CSR Matrix Approach Refered from: https://www.kaggle.com/dvasyukova/a-linear-model-on-apps-and-labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will Construct One-Hot Encoding for Phone Brand, Phone Model, Apps, App Labels using the Below CSR Matrix Constructor:\n",
    "\n",
    "csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
    "\n",
    "where ``data``, ``row_ind`` and ``col_ind`` satisfy the\n",
    "relationship ``a[row_ind[k], col_ind[k]] = data[k]``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Brand One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 131)\n",
      "(112071, 131)\n"
     ]
    }
   ],
   "source": [
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "Xtr_brand = csr_matrix((np.ones(g_a_tr.shape[0]), # Number of Rows/Devices\n",
    "                       (g_a_tr.trainrow, g_a_tr.phone_brand)))\n",
    "Xte_brand = csr_matrix((np.ones(g_a_te.shape[0]), # Number of Rows/Devices\n",
    "                       (g_a_te.testrow, g_a_te.phone_brand)))\n",
    "print(Xtr_brand.shape)\n",
    "print(Xte_brand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Model One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 1599)\n",
      "(112071, 1599)\n"
     ]
    }
   ],
   "source": [
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "Xtr_model = csr_matrix((np.ones(g_a_tr.shape[0]), # Number of Rows/Devices\n",
    "                       (g_a_tr.trainrow, g_a_tr.device_model)))\n",
    "Xte_model = csr_matrix((np.ones(g_a_te.shape[0]), # Number of Rows/Devices\n",
    "                       (g_a_te.testrow, g_a_te.device_model)))\n",
    "print(Xtr_model.shape)\n",
    "print(Xte_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74645, 1730)\n",
      "(112071, 1730)\n"
     ]
    }
   ],
   "source": [
    "X_tr_o_h=hstack((Xtr_brand,Xtr_model),format='csr')\n",
    "X_te_o_h=hstack((Xte_brand,Xte_model),format='csr')\n",
    "\n",
    "print(X_tr_o_h.shape)\n",
    "print(X_te_o_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Devices With No Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Brand One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 131)\n",
      "(76877, 131)\n"
     ]
    }
   ],
   "source": [
    "X_tr_no_event_brand = csr_matrix((np.ones(train_no_events.shape[0]), # Number of Rows/Devices\n",
    "                       (train_no_events.trainrow, train_no_events.phone_brand)), \n",
    "                              shape=(train_no_events.shape[0],n_brands))\n",
    "X_te_no_event_brand = csr_matrix((np.ones(test_no_events.shape[0]), # Number of Rows/Devices\n",
    "                       (test_no_events.testrow, test_no_events.phone_brand)),\n",
    "                             shape=(test_no_events.shape[0],n_brands))\n",
    "print(X_tr_no_event_brand.shape)\n",
    "print(X_te_no_event_brand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Model One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 1599)\n",
      "(76877, 1599)\n"
     ]
    }
   ],
   "source": [
    "X_tr_no_event_model = csr_matrix((np.ones(train_no_events.shape[0]), # Number of Rows/Devices\n",
    "                       (train_no_events.trainrow, train_no_events.device_model)), \n",
    "                              shape=(train_no_events.shape[0],n_models))\n",
    "X_te_no_event_model= csr_matrix((np.ones(test_no_events.shape[0]), # Number of Rows/Devices\n",
    "                       (test_no_events.testrow, test_no_events.device_model)),\n",
    "                             shape=(test_no_events.shape[0],n_models))\n",
    "print(X_tr_no_event_model.shape)\n",
    "print(X_te_no_event_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51336, 1730)\n",
      "(76877, 1730)\n"
     ]
    }
   ],
   "source": [
    "X_tr_no_events_o_h=hstack((X_tr_no_event_brand,X_tr_no_event_model),format='csr')\n",
    "X_te_no_events_o_h=hstack((X_te_no_event_brand,X_te_no_event_model),format='csr')\n",
    "\n",
    "print(X_tr_no_events_o_h.shape)\n",
    "print(X_te_no_events_o_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving One-hot encoded Matrices\n",
    "save_sparse('Train_Noevents_One_hot_brand_model_matrix',X_train_noevents_one_hot)\n",
    "save_sparse('Test_Noevents_One_hot_brand_model_matrix',X_test_noevents_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Devices With Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Brand One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Brand One-hot Shape:  (23309, 131)\n",
      "Test Brand One-hot Shape:  (35194, 131)\n"
     ]
    }
   ],
   "source": [
    "X_tr_event_brand = csr_matrix((np.ones(train_events.shape[0]), # Number of Rows/Devices\n",
    "                       (train_events.trainrow, train_events.phone_brand)), \n",
    "                              shape=(train_events.shape[0],n_brands))\n",
    "X_te_event_brand = csr_matrix((np.ones(test_events.shape[0]), # Number of Rows/Devices\n",
    "                       (test_events.testrow, test_events.phone_brand)),\n",
    "                             shape=(test_events.shape[0],n_brands))\n",
    "print(\"Train Brand One-hot Shape: \",X_tr_event_brand.shape)\n",
    "print(\"Test Brand One-hot Shape: \",X_te_event_brand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Phone Model One-Hot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Brand One-hot Shape:  (23309, 1667)\n",
      "Test Brand One-hot Shape:  (35194, 1667)\n"
     ]
    }
   ],
   "source": [
    "X_tr_event_model = csr_matrix((np.ones(train_events.shape[0]), # Number of Rows/Devices\n",
    "                       (train_events.trainrow, train_events.device_model)), \n",
    "                              shape=(train_events.shape[0],n_events_models))\n",
    "X_te_event_model = csr_matrix((np.ones(test_events.shape[0]), # Number of Rows/Devices\n",
    "                       (test_events.testrow, test_events.device_model)),\n",
    "                             shape=(test_events.shape[0],n_events_models))\n",
    "print(\"Train Brand One-hot Shape: \",X_tr_event_model.shape)\n",
    "print(\"Test Brand One-hot Shape: \",X_te_event_model.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Apps One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Event Apps One-hot Shape:  (23309, 19237)\n",
      "Test Event Apps One-hot Shape:  (35194, 19237)\n"
     ]
    }
   ],
   "source": [
    "d = apps_on_devices.dropna(subset=['trainrow'])\n",
    "X_tr_event_app = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.app)), \n",
    "                      shape=(train_events.shape[0],n_apps))\n",
    "#Since the Deviceapps has both train and test columns merged to create Test Apps One-Hot we will Drop all Nan of Test Row\n",
    "#Once we remove Nan in Test Rows we will get the Apps in Test Data and we create CSR Matrix for those rows\n",
    "d = apps_on_devices.dropna(subset=['testrow'])\n",
    "X_te_event_app = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.app)), \n",
    "                      shape=(test_events.shape[0],n_apps))\n",
    "print(\"Train Event Apps One-hot Shape: \",X_tr_event_app.shape)\n",
    "print(\"Test Event Apps One-hot Shape: \",X_te_event_app.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Labels One-Hot Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Event Labels One-hot Shape:  (23309, 492)\n",
      "Test Event Labels One-hot Shape:  (35194, 492)\n"
     ]
    }
   ],
   "source": [
    "d = labels_on_devices.dropna(subset=['trainrow'])\n",
    "X_tr_event_label = csr_matrix((np.ones(d.shape[0]), (d.trainrow, d.label)), \n",
    "                      shape=(train_events.shape[0],n_labels))\n",
    "#Since the Devicelabels has both train and test columns merged to create Test Labels One-Hot we will Drop all Nan of Test Row\n",
    "#Once we remove Nan in Test Rows we will get the Labels in Test Data and we create CSR Matrix for those rows\n",
    "d = labels_on_devices.dropna(subset=['testrow'])\n",
    "X_te_event_label = csr_matrix((np.ones(d.shape[0]), (d.testrow, d.label)), \n",
    "                      shape=(test_events.shape[0],n_labels))\n",
    "print(\"Train Event Labels One-hot Shape: \",X_tr_event_label.shape)\n",
    "print(\"Test Event Labels One-hot Shape: \",X_te_event_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Hours TFIDF Vector Encodings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 24)\n",
      "(35194, 24)\n"
     ]
    }
   ],
   "source": [
    "encode=TfidfVectorizer().fit(train_events[\"event_hours\"].values)\n",
    "X_tr_event_hours=encode.transform(train_events[\"event_hours\"].values)\n",
    "X_te_event_hours=encode.transform(test_events[\"event_hours\"].values)\n",
    "print(X_tr_event_hours.shape)\n",
    "print(X_te_event_hours.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Hour Bins One-Hot Encodings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 4)\n",
      "(35194, 4)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_5=CountVectorizer(binary=True)\n",
    "vectorizer_5.fit(train_events['event_hours_bins'].values)\n",
    "\n",
    "X_tr_event_hours_bins = vectorizer_5.transform(train_events['event_hours_bins'].values)\n",
    "X_te_event_hours_bins= vectorizer_5.transform(test_events['event_hours_bins'].values)\n",
    "\n",
    "print(X_tr_event_hours_bins.shape)\n",
    "print(X_te_event_hours_bins.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Event Day TFIDF Encodings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 7)\n",
      "(35194, 7)\n"
     ]
    }
   ],
   "source": [
    "encode=TfidfVectorizer().fit(train_events[\"event_day\"].values)\n",
    "X_tr_event_day=encode.transform(train_events[\"event_day\"].values)\n",
    "X_te_event_day=encode.transform(test_events[\"event_day\"].values)\n",
    "print(X_tr_event_day.shape)\n",
    "print(X_te_event_day.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardizing Latitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 1)\n",
      "(35194, 1)\n"
     ]
    }
   ],
   "source": [
    "encode=StandardScaler().fit(train_events['event_median_latitude'].values.reshape(-1,1))\n",
    "X_tr_event_latitude=encode.transform(train_events['event_median_latitude'].values.reshape(-1,1))\n",
    "X_te_event_latitude=encode.transform(test_events['event_median_latitude'].values.reshape(-1,1))\n",
    "print(X_tr_event_latitude.shape)\n",
    "print(X_te_event_latitude.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standardizing Longitude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 1)\n",
      "(35194, 1)\n"
     ]
    }
   ],
   "source": [
    "encode=StandardScaler().fit(train_events['event_median_longitude'].values.reshape(-1,1))\n",
    "X_tr_event_longitude=encode.transform(train_events['event_median_longitude'].values.reshape(-1,1))\n",
    "X_te_event_longitude=encode.transform(test_events['event_median_longitude'].values.reshape(-1,1))\n",
    "print(X_tr_event_longitude.shape)\n",
    "print(X_te_event_longitude.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apps is_active TFIDF Vector Encodings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 2)\n",
      "(35194, 2)\n"
     ]
    }
   ],
   "source": [
    "encode=TfidfVectorizer().fit(train_events[\"app_active\"].values)\n",
    "X_tr_event_app_active=encode.transform(train_events[\"app_active\"].values)\n",
    "X_te_event_app_active=encode.transform(test_events[\"app_active\"].values)\n",
    "print(X_tr_event_app_active.shape)\n",
    "print(X_te_event_app_active.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_event_hours=X_tr_event_hours.tocsr()\n",
    "X_te_event_hours=X_te_event_hours.tocsr()\n",
    "X_tr_event_hours_bins=X_tr_event_hours_bins.tocsr()\n",
    "X_te_event_hours_bins=X_te_event_hours_bins.tocsr()\n",
    "X_tr_event_day=X_tr_event_day.tocsr()\n",
    "X_te_event_day=X_te_event_day.tocsr()\n",
    "X_tr_event_app_active=X_tr_event_app_active.tocsr()\n",
    "X_te_event_app_active=X_te_event_app_active.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23309, 21566)\n",
      "(35194, 21566)\n"
     ]
    }
   ],
   "source": [
    "X_tr_event_o_h=hstack((X_tr_event_app,X_tr_event_model,X_tr_event_brand,X_tr_event_label,X_tr_event_hours,X_tr_event_hours_bins,X_tr_event_longitude,X_tr_event_latitude,X_tr_event_app_active,X_tr_event_day),format='csr')\n",
    "X_te_event_o_h=hstack((X_te_event_app,X_te_event_model,X_te_event_brand,X_te_event_label,X_te_event_hours,X_te_event_hours_bins,X_te_event_longitude,X_te_event_latitude,X_te_event_app_active,X_te_event_day),format='csr')\n",
    "print(X_tr_event_o_h.shape)\n",
    "print(X_te_event_o_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving One-hot encoded Matrices\n",
    "save_sparse('Train_Events_matrix',X_tr_event_o_h)\n",
    "save_sparse('Test_Events_matrix',X_te_event_o_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Devices without Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=g_a_tr.drop([\"class\",\"trainrow\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/f3/870cde99c7b82170542b2eb79f0d7ec587cf1cdca3a950b56d9429ecc7d9/catboost-0.23-cp37-none-win_amd64.whl (63.6MB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/cc/c62100906d30f95d46451c15eb407da7db201e30f42008f3643945910373/graphviz-0.14-py2.py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (1.16.4)\n",
      "Requirement already satisfied: plotly in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (4.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (0.24.2)\n",
      "Requirement already satisfied: six in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (2.8.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from plotly->catboost) (1.3.3)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->catboost) (2019.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (41.0.1)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-0.23 graphviz-0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, cv_1, y_train_1, y_cv_1 = train_test_split(train_data, y_data,stratify=y_data,test_size=0.15,random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier,Pool\n",
    "categorical_features_indices = [0,1,2]\n",
    "train_dataset = Pool(data=train_1,\n",
    "                     label=y_train_1,\n",
    "                     cat_features=categorical_features_indices)\n",
    "\n",
    "eval_dataset = Pool(data=cv_1,\n",
    "                    label=y_cv_1,\n",
    "                    cat_features=categorical_features_indices)\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model_cat_1 = CatBoostClassifier(n_estimators=1500,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "# Fit model\n",
    "model_cat_1.fit(train_dataset,verbose=False)\n",
    "pred_proba_1 = model.predict_proba(eval_dataset)\n",
    "\n",
    "model_cat_2 = CatBoostClassifier(n_estimators=2500,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "model_cat_2.fit(train_dataset,verbose=False)\n",
    "pred_proba_2 = model.predict_proba(eval_dataset)\n",
    "\n",
    "model_cat_3 = CatBoostClassifier(n_estimators=3500,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "model_cat_3.fit(train_dataset,verbose=False)\n",
    "pred_proba_3 = model.predict_proba(eval_dataset)\n",
    "\n",
    "model_cat_4 = CatBoostClassifier(n_estimators=4500,\n",
    "                           loss_function='MultiClass')\n",
    "\n",
    "model_cat_4.fit(train_dataset,verbose=False)\n",
    "pred_proba_4 = model.predict_proba(eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test_no_events.drop([\"testrow\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "events=[]\n",
    "for i in range(len(test)):\n",
    "    events.append(\"False\")\n",
    "test[\"events\"]=events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Pool(data=test,\n",
    "                    \n",
    "                    cat_features=categorical_features_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_1=model_cat_1.predict_proba(test_dataset)\n",
    "test_pred_2=model_cat_2.predict_proba(test_dataset)\n",
    "test_pred_3=model_cat_3.predict_proba(test_dataset)\n",
    "test_pred_4=model_cat_4.predict_proba(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(test_pred_1.shape[0]):\n",
    "    for j in range(test_pred_1.shape[1]):\n",
    "        test_pred[i][j]=(test_pred_1[i][j]+test_pred_2[i][j]+test_pred_3[i][j]+test_pred_4[i][j])/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Test Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed(\"test_pred_catboost.npz\",test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: h5py in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (5.1.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\sinagam pradeep\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization,Input,PReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping,TensorBoard\n",
    "early_stop_1=EarlyStopping(monitor='val_loss',patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data=g_a_tr['class'].values\n",
    "train_1, cv_1, y_train_1, y_cv_1 = train_test_split(X_tr_o_h, y_data,stratify=y_data,test_size=0.15,random_state=18)\n",
    "test_1=X_te_no_events_o_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Architecture Refered from: https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_no_events(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=input_shape))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 256)               443136    \n",
      "_________________________________________________________________\n",
      "p_re_lu_17 (PReLU)           (None, 256)               256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "p_re_lu_18 (PReLU)           (None, 64)                64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 12)                780       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 461,964\n",
      "Trainable params: 461,324\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_no_events(X_tr_o_h.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_no_events_models(seeds):\n",
    "\n",
    "    model_list_no_events=[]\n",
    "    avg_cv_loss=0\n",
    "    for i in range(len(seeds)):\n",
    "        train, cv, y_train, y_cv = train_test_split(X_tr_o_h, y_data,stratify=y_data,test_size=0.15,random_state=seeds[i])\n",
    "        y_train_nn=np_utils.to_categorical(y_train)\n",
    "        y_cv_nn=np_utils.to_categorical(y_cv)\n",
    "        model=model_no_events(train.shape[1])\n",
    "        logdir = \"no_events\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        t=TensorBoard(log_dir=logdir)\n",
    "        model.fit(train, y_train_nn, batch_size=350, epochs=30, verbose=2, validation_data=(cv, y_cv_nn),callbacks=[early_stop_1,t])\n",
    "        model_cv_prediction=model.predict_proba(cv)\n",
    "        cv_loss=log_loss(y_cv, model_cv_prediction)\n",
    "        print(\"CV Log Loss of Best Weights Model in Current Run: \",cv_loss)\n",
    "        model_list_no_events.append(model)\n",
    "        avg_cv_loss+=cv_loss\n",
    "    avg_cv_loss/=len(seeds)\n",
    "    print(\"Average CV Loss of \"+str(len(seeds))+\" Runs :\",avg_cv_loss)\n",
    "    return model_list_no_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds=[1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63448 samples, validate on 11197 samples\n",
      "Epoch 1/30\n",
      " - 9s - loss: 3.0035 - accuracy: 0.1015 - val_loss: 2.4398 - val_accuracy: 0.1149\n",
      "Epoch 2/30\n",
      " - 8s - loss: 2.5282 - accuracy: 0.1256 - val_loss: 2.4177 - val_accuracy: 0.1349\n",
      "Epoch 3/30\n",
      " - 8s - loss: 2.4333 - accuracy: 0.1412 - val_loss: 2.4031 - val_accuracy: 0.1478\n",
      "Epoch 4/30\n",
      " - 7s - loss: 2.4067 - accuracy: 0.1493 - val_loss: 2.3958 - val_accuracy: 0.1503\n",
      "Epoch 5/30\n",
      " - 8s - loss: 2.3927 - accuracy: 0.1557 - val_loss: 2.3932 - val_accuracy: 0.1503\n",
      "Epoch 6/30\n",
      " - 7s - loss: 2.3850 - accuracy: 0.1609 - val_loss: 2.3935 - val_accuracy: 0.1529\n",
      "Epoch 7/30\n",
      " - 8s - loss: 2.3790 - accuracy: 0.1608 - val_loss: 2.3937 - val_accuracy: 0.1541\n",
      "Epoch 8/30\n",
      " - 8s - loss: 2.3731 - accuracy: 0.1642 - val_loss: 2.3938 - val_accuracy: 0.1541\n",
      "Epoch 9/30\n",
      " - 8s - loss: 2.3679 - accuracy: 0.1667 - val_loss: 2.3958 - val_accuracy: 0.1484\n",
      "Epoch 10/30\n",
      " - 7s - loss: 2.3650 - accuracy: 0.1685 - val_loss: 2.3976 - val_accuracy: 0.1492\n",
      "CV Log Loss of Best Weights Model in Current Run:  2.3931859521617995\n",
      "Train on 63448 samples, validate on 11197 samples\n",
      "Epoch 1/30\n",
      " - 8s - loss: 2.9602 - accuracy: 0.1004 - val_loss: 2.4484 - val_accuracy: 0.1424\n",
      "Epoch 2/30\n",
      " - 8s - loss: 2.5148 - accuracy: 0.1264 - val_loss: 2.4207 - val_accuracy: 0.1500\n",
      "Epoch 3/30\n",
      " - 7s - loss: 2.4316 - accuracy: 0.1390 - val_loss: 2.4032 - val_accuracy: 0.1489\n",
      "Epoch 4/30\n",
      " - 7s - loss: 2.4047 - accuracy: 0.1500 - val_loss: 2.3926 - val_accuracy: 0.1548\n",
      "Epoch 5/30\n",
      " - 7s - loss: 2.3936 - accuracy: 0.1552 - val_loss: 2.3896 - val_accuracy: 0.1558\n",
      "Epoch 6/30\n",
      " - 8s - loss: 2.3860 - accuracy: 0.1603 - val_loss: 2.3881 - val_accuracy: 0.1563\n",
      "Epoch 7/30\n",
      " - 7s - loss: 2.3810 - accuracy: 0.1613 - val_loss: 2.3873 - val_accuracy: 0.1543\n",
      "Epoch 8/30\n",
      " - 7s - loss: 2.3741 - accuracy: 0.1621 - val_loss: 2.3865 - val_accuracy: 0.1572\n",
      "Epoch 9/30\n",
      " - 7s - loss: 2.3693 - accuracy: 0.1657 - val_loss: 2.3882 - val_accuracy: 0.1523\n",
      "Epoch 10/30\n",
      " - 8s - loss: 2.3648 - accuracy: 0.1685 - val_loss: 2.3903 - val_accuracy: 0.1538\n",
      "Epoch 11/30\n",
      " - 7s - loss: 2.3615 - accuracy: 0.1690 - val_loss: 2.3916 - val_accuracy: 0.1529\n",
      "Epoch 12/30\n",
      " - 7s - loss: 2.3572 - accuracy: 0.1699 - val_loss: 2.3934 - val_accuracy: 0.1546\n",
      "Epoch 13/30\n",
      " - 7s - loss: 2.3546 - accuracy: 0.1710 - val_loss: 2.3940 - val_accuracy: 0.1563\n",
      "CV Log Loss of Best Weights Model in Current Run:  2.3864819200760534\n",
      "Train on 63448 samples, validate on 11197 samples\n",
      "Epoch 1/30\n",
      " - 8s - loss: 2.9888 - accuracy: 0.1001 - val_loss: 2.4621 - val_accuracy: 0.1249\n",
      "Epoch 2/30\n",
      " - 7s - loss: 2.5292 - accuracy: 0.1213 - val_loss: 2.4233 - val_accuracy: 0.1363\n",
      "Epoch 3/30\n",
      " - 7s - loss: 2.4350 - accuracy: 0.1424 - val_loss: 2.4042 - val_accuracy: 0.1446\n",
      "Epoch 4/30\n",
      " - 8s - loss: 2.4064 - accuracy: 0.1496 - val_loss: 2.3947 - val_accuracy: 0.1530\n",
      "Epoch 5/30\n",
      " - 7s - loss: 2.3953 - accuracy: 0.1549 - val_loss: 2.3912 - val_accuracy: 0.1545\n",
      "Epoch 6/30\n",
      " - 7s - loss: 2.3867 - accuracy: 0.1594 - val_loss: 2.3898 - val_accuracy: 0.1533\n",
      "Epoch 7/30\n",
      " - 7s - loss: 2.3813 - accuracy: 0.1606 - val_loss: 2.3904 - val_accuracy: 0.1505\n",
      "Epoch 8/30\n",
      " - 8s - loss: 2.3763 - accuracy: 0.1645 - val_loss: 2.3895 - val_accuracy: 0.1501\n",
      "Epoch 9/30\n",
      " - 7s - loss: 2.3709 - accuracy: 0.1663 - val_loss: 2.3913 - val_accuracy: 0.1509\n",
      "Epoch 10/30\n",
      " - 8s - loss: 2.3658 - accuracy: 0.1678 - val_loss: 2.3918 - val_accuracy: 0.1512\n",
      "Epoch 11/30\n",
      " - 8s - loss: 2.3620 - accuracy: 0.1689 - val_loss: 2.3947 - val_accuracy: 0.1516\n",
      "Epoch 12/30\n",
      " - 8s - loss: 2.3580 - accuracy: 0.1704 - val_loss: 2.3956 - val_accuracy: 0.1501\n",
      "Epoch 13/30\n",
      " - 7s - loss: 2.3547 - accuracy: 0.1720 - val_loss: 2.3960 - val_accuracy: 0.1487\n",
      "CV Log Loss of Best Weights Model in Current Run:  2.3894834297091085\n",
      "Train on 63448 samples, validate on 11197 samples\n",
      "Epoch 1/30\n",
      " - 8s - loss: 2.9956 - accuracy: 0.1020 - val_loss: 2.4557 - val_accuracy: 0.1287\n",
      "Epoch 2/30\n",
      " - 7s - loss: 2.5307 - accuracy: 0.1238 - val_loss: 2.4216 - val_accuracy: 0.1287\n",
      "Epoch 3/30\n",
      " - 7s - loss: 2.4344 - accuracy: 0.1414 - val_loss: 2.4042 - val_accuracy: 0.1424\n",
      "Epoch 4/30\n",
      " - 7s - loss: 2.4059 - accuracy: 0.1508 - val_loss: 2.3937 - val_accuracy: 0.1533\n",
      "Epoch 5/30\n",
      " - 7s - loss: 2.3931 - accuracy: 0.1550 - val_loss: 2.3920 - val_accuracy: 0.1534\n",
      "Epoch 6/30\n",
      " - 8s - loss: 2.3863 - accuracy: 0.1592 - val_loss: 2.3911 - val_accuracy: 0.1557\n",
      "Epoch 7/30\n",
      " - 7s - loss: 2.3814 - accuracy: 0.1615 - val_loss: 2.3906 - val_accuracy: 0.1532\n",
      "Epoch 8/30\n",
      " - 7s - loss: 2.3753 - accuracy: 0.1637 - val_loss: 2.3920 - val_accuracy: 0.1528\n",
      "Epoch 9/30\n",
      " - 7s - loss: 2.3709 - accuracy: 0.1658 - val_loss: 2.3930 - val_accuracy: 0.1529\n",
      "Epoch 10/30\n",
      " - 8s - loss: 2.3658 - accuracy: 0.1672 - val_loss: 2.3946 - val_accuracy: 0.1523\n",
      "Epoch 11/30\n",
      " - 7s - loss: 2.3613 - accuracy: 0.1670 - val_loss: 2.3960 - val_accuracy: 0.1536\n",
      "Epoch 12/30\n",
      " - 7s - loss: 2.3585 - accuracy: 0.1682 - val_loss: 2.3967 - val_accuracy: 0.1553\n",
      "CV Log Loss of Best Weights Model in Current Run:  2.3905558474119024\n",
      "Train on 63448 samples, validate on 11197 samples\n",
      "Epoch 1/30\n",
      " - 9s - loss: 2.9652 - accuracy: 0.1026 - val_loss: 2.4792 - val_accuracy: 0.1149\n",
      "Epoch 2/30\n",
      " - 8s - loss: 2.5173 - accuracy: 0.1277 - val_loss: 2.4299 - val_accuracy: 0.1276\n",
      "Epoch 3/30\n",
      " - 9s - loss: 2.4298 - accuracy: 0.1422 - val_loss: 2.4046 - val_accuracy: 0.1457\n",
      "Epoch 4/30\n",
      " - 9s - loss: 2.4034 - accuracy: 0.1510 - val_loss: 2.3956 - val_accuracy: 0.1480\n",
      "Epoch 5/30\n",
      " - 8s - loss: 2.3929 - accuracy: 0.1561 - val_loss: 2.3917 - val_accuracy: 0.1467\n",
      "Epoch 6/30\n",
      " - 8s - loss: 2.3849 - accuracy: 0.1583 - val_loss: 2.3923 - val_accuracy: 0.1472\n",
      "Epoch 7/30\n",
      " - 7s - loss: 2.3805 - accuracy: 0.1606 - val_loss: 2.3917 - val_accuracy: 0.1483\n",
      "Epoch 8/30\n",
      " - 8s - loss: 2.3745 - accuracy: 0.1639 - val_loss: 2.3924 - val_accuracy: 0.1508\n",
      "Epoch 9/30\n",
      " - 8s - loss: 2.3694 - accuracy: 0.1663 - val_loss: 2.3949 - val_accuracy: 0.1508\n",
      "Epoch 10/30\n",
      " - 8s - loss: 2.3653 - accuracy: 0.1673 - val_loss: 2.3966 - val_accuracy: 0.1466\n",
      "CV Log Loss of Best Weights Model in Current Run:  2.391652160790857\n",
      "Average CV Loss of 5 Runs : 2.390271862029944\n"
     ]
    }
   ],
   "source": [
    "model_list_no_events=get_network_no_events_models(random_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_avg_nn=np.zeros((test_1.shape[0],12))\n",
    "\n",
    "for i in range(len(model_list_no_events)):\n",
    "    test_pred=model_list_no_events[i].predict_proba(test_1)\n",
    "    test_pred_avg_nn+=test_pred\n",
    "test_pred_avg_nn/=len(model_list_no_events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Test Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('y_test_pred_nn.npz',test_pred_avg_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devices with Events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train, CV Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data_events=train_events['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2, cv_2, y_train_2, y_cv_2 = train_test_split(X_tr_event_o_h,y_data_events,stratify=y_data_events,test_size=0.2,random_state=9)\n",
    "test_2=X_te_event_o_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_nn_3=np_utils.to_categorical(y_train_2)\n",
    "y_cv_nn_3=np_utils.to_categorical(y_cv_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Architecture Refered from: https://www.kaggle.com/c/talkingdata-mobile-user-demographics/discussion/23424"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dropout in the input Layer adds value and variability for predictions and is helpful for taking avaerage of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn(input_dim,output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.15, input_shape=(input_dim,)))\n",
    "    model.add(Dense(240, init='uniform'))\n",
    "    model.add(PReLU(init='zero'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(240, init='uniform'))\n",
    "    model.add(PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.35))\n",
    "    model.add(Dense(260, init='uniform'))\n",
    "    model.add(PReLU(init='zero', weights=None))\n",
    "    model.add(Dropout(0.40))\n",
    "    model.add(Dense(output_dim, init='uniform'))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    opt = Adagrad(lr=0.008, epsilon=1e-08)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_18 (Dropout)         (None, 21566)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 240)               5176080   \n",
      "_________________________________________________________________\n",
      "p_re_lu_13 (PReLU)           (None, 240)               240       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 240)               57840     \n",
      "_________________________________________________________________\n",
      "p_re_lu_14 (PReLU)           (None, 240)               240       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 240)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 260)               62660     \n",
      "_________________________________________________________________\n",
      "p_re_lu_15 (PReLU)           (None, 260)               260       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 260)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 12)                3132      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 5,300,452\n",
      "Trainable params: 5,300,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_nn(X_tr_event_o_h.shape[1],12)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Function Takes number of models as input, and trains the required number of models, plots scalar graph for each model in Tensor Board, prints the avg cv loss of all the models, stores the model in a list and returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(n_models):\n",
    "\n",
    "    model_list=[]\n",
    "    avg_cv_loss=0\n",
    "    for i in range(n_models):\n",
    "        model=model_nn(train_2.shape[1],12)\n",
    "        logdir = os.path.join(\"logs_301\",\"Model_2_1.\"+str(i+1))\n",
    "        t_callback=TensorBoard(log_dir=logdir)\n",
    "        model.fit(train_2, y_train_nn_3, batch_size=149, epochs=20, verbose=1, validation_data=(cv_2, y_cv_nn_3),callbacks=[early_stop_1,t_callback])\n",
    "        model_cv_prediction=model.predict_proba(cv_2)\n",
    "        cv_loss=log_loss(y_cv_2, model_cv_prediction)\n",
    "        print(\"CV Log Loss of Best Weights Model in Current Run: \",cv_loss)\n",
    "        model_list.append(model)\n",
    "        avg_cv_loss+=cv_loss\n",
    "    avg_cv_loss/=n_models\n",
    "    print(\"Average CV Loss of \"+str(n_models)+\" Runs :\",avg_cv_loss)\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18647 samples, validate on 4662 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Sinagam Pradeep\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sinagam Pradeep\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 21s 1ms/step - loss: 2.2981 - accuracy: 0.1767 - val_loss: 2.1424 - val_accuracy: 0.2653\n",
      "WARNING:tensorflow:From C:\\Users\\Sinagam Pradeep\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 959us/step - loss: 2.1420 - accuracy: 0.2400 - val_loss: 2.0470 - val_accuracy: 0.2722\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 2.0724 - accuracy: 0.2628 - val_loss: 2.0110 - val_accuracy: 0.2967\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 960us/step - loss: 2.0334 - accuracy: 0.2746 - val_loss: 1.9917 - val_accuracy: 0.3112\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.9976 - accuracy: 0.2892 - val_loss: 2.0079 - val_accuracy: 0.2930\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.9726 - accuracy: 0.2973 - val_loss: 1.9490 - val_accuracy: 0.3207\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 973us/step - loss: 1.9476 - accuracy: 0.3081 - val_loss: 1.9451 - val_accuracy: 0.3239\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 955us/step - loss: 1.9203 - accuracy: 0.3155 - val_loss: 1.9358 - val_accuracy: 0.3205\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 958us/step - loss: 1.9023 - accuracy: 0.3192 - val_loss: 1.9312 - val_accuracy: 0.3235\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.8875 - accuracy: 0.3271 - val_loss: 1.9394 - val_accuracy: 0.3207\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 974us/step - loss: 1.8728 - accuracy: 0.3290 - val_loss: 1.9270 - val_accuracy: 0.3228\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.8503 - accuracy: 0.3402 - val_loss: 1.9369 - val_accuracy: 0.3127\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.8397 - accuracy: 0.3412 - val_loss: 1.9251 - val_accuracy: 0.3269\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 962us/step - loss: 1.8306 - accuracy: 0.3457 - val_loss: 1.9188 - val_accuracy: 0.3185\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.8142 - accuracy: 0.3501 - val_loss: 1.9188 - val_accuracy: 0.3233\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 962us/step - loss: 1.8119 - accuracy: 0.3475 - val_loss: 1.9207 - val_accuracy: 0.3250\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 961us/step - loss: 1.7899 - accuracy: 0.3579 - val_loss: 1.9176 - val_accuracy: 0.3280\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 960us/step - loss: 1.7773 - accuracy: 0.3652 - val_loss: 1.9230 - val_accuracy: 0.3202\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.7667 - accuracy: 0.3641 - val_loss: 1.9212 - val_accuracy: 0.3260\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.7576 - accuracy: 0.3654 - val_loss: 1.9213 - val_accuracy: 0.3273\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9213292464798302\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 2.2876 - accuracy: 0.1851 - val_loss: 2.1446 - val_accuracy: 0.2471\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 2.1377 - accuracy: 0.2412 - val_loss: 2.0427 - val_accuracy: 0.2864\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 2.0754 - accuracy: 0.2634 - val_loss: 2.0136 - val_accuracy: 0.3024\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 2.0344 - accuracy: 0.2809 - val_loss: 1.9895 - val_accuracy: 0.3076\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 1.9963 - accuracy: 0.2882 - val_loss: 1.9663 - val_accuracy: 0.3153\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.9667 - accuracy: 0.3020 - val_loss: 1.9524 - val_accuracy: 0.3215\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 962us/step - loss: 1.9491 - accuracy: 0.3081 - val_loss: 1.9438 - val_accuracy: 0.3207\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.9253 - accuracy: 0.3122 - val_loss: 1.9441 - val_accuracy: 0.3145\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 1.9037 - accuracy: 0.3205 - val_loss: 1.9280 - val_accuracy: 0.3265\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.8875 - accuracy: 0.3256 - val_loss: 1.9259 - val_accuracy: 0.3222\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8682 - accuracy: 0.3332 - val_loss: 1.9201 - val_accuracy: 0.3280\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 991us/step - loss: 1.8554 - accuracy: 0.3352 - val_loss: 1.9211 - val_accuracy: 0.3284\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.8478 - accuracy: 0.3417 - val_loss: 1.9142 - val_accuracy: 0.3290\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 1.8241 - accuracy: 0.3497 - val_loss: 1.9176 - val_accuracy: 0.3275\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.8109 - accuracy: 0.3500 - val_loss: 1.9127 - val_accuracy: 0.3305\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.7988 - accuracy: 0.3557 - val_loss: 1.9118 - val_accuracy: 0.3286\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.7800 - accuracy: 0.3573 - val_loss: 1.9214 - val_accuracy: 0.3314\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 1.7744 - accuracy: 0.3621 - val_loss: 1.9180 - val_accuracy: 0.3271\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.7578 - accuracy: 0.3657 - val_loss: 1.9165 - val_accuracy: 0.3303\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.7478 - accuracy: 0.3721 - val_loss: 1.9224 - val_accuracy: 0.3280\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.922371432868183\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 2.2966 - accuracy: 0.1820 - val_loss: 2.1437 - val_accuracy: 0.2544\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 2.1412 - accuracy: 0.2447 - val_loss: 2.0476 - val_accuracy: 0.2853\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 2.0651 - accuracy: 0.2685 - val_loss: 2.0208 - val_accuracy: 0.2960\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 2.0238 - accuracy: 0.2829 - val_loss: 1.9829 - val_accuracy: 0.3037\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.9979 - accuracy: 0.2888 - val_loss: 1.9848 - val_accuracy: 0.3048\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.9608 - accuracy: 0.2989 - val_loss: 1.9560 - val_accuracy: 0.3187\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.9426 - accuracy: 0.3054 - val_loss: 1.9452 - val_accuracy: 0.3145\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.9217 - accuracy: 0.3138 - val_loss: 1.9375 - val_accuracy: 0.3190\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.8981 - accuracy: 0.3270 - val_loss: 1.9348 - val_accuracy: 0.3205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 962us/step - loss: 1.8861 - accuracy: 0.3264 - val_loss: 1.9307 - val_accuracy: 0.3187\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 974us/step - loss: 1.8706 - accuracy: 0.3340 - val_loss: 1.9308 - val_accuracy: 0.3200\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.8437 - accuracy: 0.3410 - val_loss: 1.9277 - val_accuracy: 0.3207\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 1.8362 - accuracy: 0.3456 - val_loss: 1.9238 - val_accuracy: 0.3235\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.8186 - accuracy: 0.3497 - val_loss: 1.9222 - val_accuracy: 0.3258\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.8078 - accuracy: 0.3523 - val_loss: 1.9257 - val_accuracy: 0.3252\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 974us/step - loss: 1.7920 - accuracy: 0.3594 - val_loss: 1.9251 - val_accuracy: 0.3265\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 960us/step - loss: 1.7839 - accuracy: 0.3615 - val_loss: 1.9277 - val_accuracy: 0.3248\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.7709 - accuracy: 0.3615 - val_loss: 1.9247 - val_accuracy: 0.3269\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.7582 - accuracy: 0.3653 - val_loss: 1.9304 - val_accuracy: 0.3222\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9222086258704048\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 2.2947 - accuracy: 0.1795 - val_loss: 2.1577 - val_accuracy: 0.2653\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 2.1379 - accuracy: 0.2413 - val_loss: 2.0320 - val_accuracy: 0.2932\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 2.0732 - accuracy: 0.2688 - val_loss: 1.9999 - val_accuracy: 0.2992\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 2.0261 - accuracy: 0.2763 - val_loss: 1.9821 - val_accuracy: 0.3130\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 1.9944 - accuracy: 0.2882 - val_loss: 1.9711 - val_accuracy: 0.3160\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.9644 - accuracy: 0.3013 - val_loss: 1.9548 - val_accuracy: 0.3205\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.9434 - accuracy: 0.3130 - val_loss: 1.9451 - val_accuracy: 0.3222\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 1.9233 - accuracy: 0.3115 - val_loss: 1.9389 - val_accuracy: 0.3260\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.9014 - accuracy: 0.3212 - val_loss: 1.9314 - val_accuracy: 0.3239\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 973us/step - loss: 1.8808 - accuracy: 0.3273 - val_loss: 1.9294 - val_accuracy: 0.3226\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8714 - accuracy: 0.3301 - val_loss: 1.9227 - val_accuracy: 0.3271\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.8570 - accuracy: 0.3354 - val_loss: 1.9243 - val_accuracy: 0.3271\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.8308 - accuracy: 0.3443 - val_loss: 1.9165 - val_accuracy: 0.3267\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.8271 - accuracy: 0.3463 - val_loss: 1.9200 - val_accuracy: 0.3263\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.8150 - accuracy: 0.3533 - val_loss: 1.9266 - val_accuracy: 0.3273\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7912 - accuracy: 0.3560 - val_loss: 1.9229 - val_accuracy: 0.3260\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7829 - accuracy: 0.3587 - val_loss: 1.9276 - val_accuracy: 0.3248\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.7708 - accuracy: 0.3661 - val_loss: 1.9349 - val_accuracy: 0.3194\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9165169085393545\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 997us/step - loss: 2.2835 - accuracy: 0.1847 - val_loss: 2.1343 - val_accuracy: 0.2460\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 2.1306 - accuracy: 0.2466 - val_loss: 2.0591 - val_accuracy: 0.2795\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 2.0583 - accuracy: 0.2719 - val_loss: 2.0013 - val_accuracy: 0.3033\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 2.0225 - accuracy: 0.2806 - val_loss: 1.9767 - val_accuracy: 0.3046\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9941 - accuracy: 0.2946 - val_loss: 1.9634 - val_accuracy: 0.3142\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 1.9608 - accuracy: 0.3035 - val_loss: 1.9467 - val_accuracy: 0.3153\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9419 - accuracy: 0.3078 - val_loss: 1.9397 - val_accuracy: 0.3151\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.9155 - accuracy: 0.3166 - val_loss: 1.9332 - val_accuracy: 0.3196\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8974 - accuracy: 0.3194 - val_loss: 1.9266 - val_accuracy: 0.3222\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.8885 - accuracy: 0.3321 - val_loss: 1.9209 - val_accuracy: 0.3256\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8655 - accuracy: 0.3367 - val_loss: 1.9208 - val_accuracy: 0.3237\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.8459 - accuracy: 0.3386 - val_loss: 1.9160 - val_accuracy: 0.3252\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.8349 - accuracy: 0.3477 - val_loss: 1.9192 - val_accuracy: 0.3310\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.8268 - accuracy: 0.3483 - val_loss: 1.9176 - val_accuracy: 0.3325\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.8038 - accuracy: 0.3532 - val_loss: 1.9212 - val_accuracy: 0.3271\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.7975 - accuracy: 0.3549 - val_loss: 1.9105 - val_accuracy: 0.3327\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.7782 - accuracy: 0.3638 - val_loss: 1.9183 - val_accuracy: 0.3301\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.7718 - accuracy: 0.3610 - val_loss: 1.9144 - val_accuracy: 0.3284\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.7578 - accuracy: 0.3691 - val_loss: 1.9178 - val_accuracy: 0.3305\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7515 - accuracy: 0.3698 - val_loss: 1.9226 - val_accuracy: 0.3335\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9225735414088219\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1000us/step - loss: 2.2885 - accuracy: 0.1881 - val_loss: 2.1406 - val_accuracy: 0.2392\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 2.1336 - accuracy: 0.2468 - val_loss: 2.0354 - val_accuracy: 0.2881\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 2.0756 - accuracy: 0.2644 - val_loss: 2.0112 - val_accuracy: 0.2934\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 2.0283 - accuracy: 0.2788 - val_loss: 1.9825 - val_accuracy: 0.3087\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.9882 - accuracy: 0.2940 - val_loss: 1.9621 - val_accuracy: 0.3130\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.9660 - accuracy: 0.3061 - val_loss: 1.9511 - val_accuracy: 0.3155\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.9404 - accuracy: 0.3120 - val_loss: 1.9409 - val_accuracy: 0.3170\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.9139 - accuracy: 0.3194 - val_loss: 1.9287 - val_accuracy: 0.3278\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8991 - accuracy: 0.3240 - val_loss: 1.9272 - val_accuracy: 0.3222\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.8779 - accuracy: 0.3302 - val_loss: 1.9255 - val_accuracy: 0.3293\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.8648 - accuracy: 0.3337 - val_loss: 1.9329 - val_accuracy: 0.3256\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.8452 - accuracy: 0.3410 - val_loss: 1.9183 - val_accuracy: 0.3350\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.8352 - accuracy: 0.3437 - val_loss: 1.9239 - val_accuracy: 0.3168\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.8152 - accuracy: 0.3460 - val_loss: 1.9187 - val_accuracy: 0.3282\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.8001 - accuracy: 0.3506 - val_loss: 1.9218 - val_accuracy: 0.3331\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.7938 - accuracy: 0.3602 - val_loss: 1.9213 - val_accuracy: 0.3250\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 964us/step - loss: 1.7869 - accuracy: 0.3585 - val_loss: 1.9222 - val_accuracy: 0.3295\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.91830617513852\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.2945 - accuracy: 0.1855 - val_loss: 2.1215 - val_accuracy: 0.2707\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 2.1398 - accuracy: 0.2489 - val_loss: 2.0385 - val_accuracy: 0.2904\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 2.0679 - accuracy: 0.2651 - val_loss: 2.0069 - val_accuracy: 0.3027\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 2.0202 - accuracy: 0.2811 - val_loss: 1.9751 - val_accuracy: 0.3145\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.9920 - accuracy: 0.2914 - val_loss: 1.9922 - val_accuracy: 0.3067\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.9690 - accuracy: 0.2994 - val_loss: 1.9507 - val_accuracy: 0.3220\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.9356 - accuracy: 0.3106 - val_loss: 1.9578 - val_accuracy: 0.3115\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.9247 - accuracy: 0.3149 - val_loss: 1.9341 - val_accuracy: 0.3192\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.9014 - accuracy: 0.3237 - val_loss: 1.9343 - val_accuracy: 0.3190\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.8818 - accuracy: 0.3265 - val_loss: 1.9294 - val_accuracy: 0.3196\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8627 - accuracy: 0.3316 - val_loss: 1.9245 - val_accuracy: 0.3200\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.8474 - accuracy: 0.3377 - val_loss: 1.9194 - val_accuracy: 0.3278\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 965us/step - loss: 1.8400 - accuracy: 0.3456 - val_loss: 1.9199 - val_accuracy: 0.3237\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.8148 - accuracy: 0.3521 - val_loss: 1.9199 - val_accuracy: 0.3215\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.8109 - accuracy: 0.3537 - val_loss: 1.9153 - val_accuracy: 0.3267\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.7889 - accuracy: 0.3648 - val_loss: 1.9184 - val_accuracy: 0.3228\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.7803 - accuracy: 0.3639 - val_loss: 1.9179 - val_accuracy: 0.3243\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.7639 - accuracy: 0.3648 - val_loss: 1.9212 - val_accuracy: 0.3258\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.7641 - accuracy: 0.3696 - val_loss: 1.9165 - val_accuracy: 0.3233\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.7441 - accuracy: 0.3697 - val_loss: 1.9240 - val_accuracy: 0.3260\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9153165954154374\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 2.2905 - accuracy: 0.1811 - val_loss: 2.1224 - val_accuracy: 0.2666\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 2.1331 - accuracy: 0.2452 - val_loss: 2.0497 - val_accuracy: 0.2906\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 2.0651 - accuracy: 0.2661 - val_loss: 1.9967 - val_accuracy: 0.3035\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 2.0219 - accuracy: 0.2799 - val_loss: 1.9887 - val_accuracy: 0.3027\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.9932 - accuracy: 0.2922 - val_loss: 1.9620 - val_accuracy: 0.3145\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.9658 - accuracy: 0.2981 - val_loss: 1.9491 - val_accuracy: 0.3194\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.9446 - accuracy: 0.3069 - val_loss: 1.9425 - val_accuracy: 0.3177\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.9130 - accuracy: 0.3172 - val_loss: 1.9357 - val_accuracy: 0.3177\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.9038 - accuracy: 0.3183 - val_loss: 1.9313 - val_accuracy: 0.3213\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.8790 - accuracy: 0.3301 - val_loss: 1.9221 - val_accuracy: 0.3224\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 966us/step - loss: 1.8667 - accuracy: 0.3342 - val_loss: 1.9218 - val_accuracy: 0.3241\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 968us/step - loss: 1.8520 - accuracy: 0.3377 - val_loss: 1.9298 - val_accuracy: 0.3153\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.8396 - accuracy: 0.3412 - val_loss: 1.9167 - val_accuracy: 0.3248\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.8231 - accuracy: 0.3498 - val_loss: 1.9201 - val_accuracy: 0.3284\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8085 - accuracy: 0.3530 - val_loss: 1.9144 - val_accuracy: 0.3258\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8001 - accuracy: 0.3510 - val_loss: 1.9154 - val_accuracy: 0.3263\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.7888 - accuracy: 0.3594 - val_loss: 1.9133 - val_accuracy: 0.3320\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 19s 998us/step - loss: 1.7725 - accuracy: 0.3618 - val_loss: 1.9178 - val_accuracy: 0.3293\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.7521 - accuracy: 0.3667 - val_loss: 1.9231 - val_accuracy: 0.3207\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 21s 1ms/step - loss: 1.7507 - accuracy: 0.3747 - val_loss: 1.9214 - val_accuracy: 0.3275\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9213689185275626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2860 - accuracy: 0.1850 - val_loss: 2.1081 - val_accuracy: 0.2557\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 21s 1ms/step - loss: 2.1260 - accuracy: 0.2468 - val_loss: 2.0465 - val_accuracy: 0.2898\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.0649 - accuracy: 0.2678 - val_loss: 2.0066 - val_accuracy: 0.3031\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 2.0241 - accuracy: 0.2785 - val_loss: 1.9780 - val_accuracy: 0.3067\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 973us/step - loss: 1.9933 - accuracy: 0.2903 - val_loss: 1.9566 - val_accuracy: 0.3145\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.9647 - accuracy: 0.2953 - val_loss: 1.9475 - val_accuracy: 0.3220\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9421 - accuracy: 0.3090 - val_loss: 1.9418 - val_accuracy: 0.3177\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.9185 - accuracy: 0.3153 - val_loss: 1.9329 - val_accuracy: 0.3205\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.9023 - accuracy: 0.3244 - val_loss: 1.9297 - val_accuracy: 0.3215\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.8875 - accuracy: 0.3273 - val_loss: 1.9255 - val_accuracy: 0.3198\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8681 - accuracy: 0.3294 - val_loss: 1.9219 - val_accuracy: 0.3224\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.8501 - accuracy: 0.3385 - val_loss: 1.9212 - val_accuracy: 0.3155\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 999us/step - loss: 1.8427 - accuracy: 0.3403 - val_loss: 1.9168 - val_accuracy: 0.3230\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8226 - accuracy: 0.3478 - val_loss: 1.9292 - val_accuracy: 0.3121\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.8067 - accuracy: 0.3550 - val_loss: 1.9190 - val_accuracy: 0.3183\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 963us/step - loss: 1.7956 - accuracy: 0.3559 - val_loss: 1.9240 - val_accuracy: 0.3243\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.7854 - accuracy: 0.3551 - val_loss: 1.9169 - val_accuracy: 0.3205\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.7718 - accuracy: 0.3640 - val_loss: 1.9187 - val_accuracy: 0.3271\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9168140035316807\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2822 - accuracy: 0.1861 - val_loss: 2.0967 - val_accuracy: 0.2555\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.1278 - accuracy: 0.2504 - val_loss: 2.0351 - val_accuracy: 0.3024\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.0569 - accuracy: 0.2708 - val_loss: 2.0050 - val_accuracy: 0.2956\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 2.0243 - accuracy: 0.2849 - val_loss: 1.9776 - val_accuracy: 0.3125\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.9875 - accuracy: 0.2941 - val_loss: 1.9665 - val_accuracy: 0.3145\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 967us/step - loss: 1.9594 - accuracy: 0.3037 - val_loss: 1.9470 - val_accuracy: 0.3224\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 973us/step - loss: 1.9338 - accuracy: 0.3124 - val_loss: 1.9424 - val_accuracy: 0.3218\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9119 - accuracy: 0.3182 - val_loss: 1.9322 - val_accuracy: 0.3192\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 19s 996us/step - loss: 1.8932 - accuracy: 0.3262 - val_loss: 1.9293 - val_accuracy: 0.3190\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.8809 - accuracy: 0.3269 - val_loss: 1.9214 - val_accuracy: 0.3224\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8680 - accuracy: 0.3353 - val_loss: 1.9377 - val_accuracy: 0.3177\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 1.8491 - accuracy: 0.3401 - val_loss: 1.9258 - val_accuracy: 0.3250\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.8257 - accuracy: 0.3458 - val_loss: 1.9288 - val_accuracy: 0.3168\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8198 - accuracy: 0.3500 - val_loss: 1.9232 - val_accuracy: 0.3245\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8015 - accuracy: 0.3517 - val_loss: 1.9229 - val_accuracy: 0.3222\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9214377848899726\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2833 - accuracy: 0.1906 - val_loss: 2.1062 - val_accuracy: 0.2688\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 2.1263 - accuracy: 0.2468 - val_loss: 2.0354 - val_accuracy: 0.2874\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.0597 - accuracy: 0.2654 - val_loss: 1.9958 - val_accuracy: 0.3031\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.0172 - accuracy: 0.2887 - val_loss: 1.9754 - val_accuracy: 0.3085\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9861 - accuracy: 0.2976 - val_loss: 1.9677 - val_accuracy: 0.3119\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.9608 - accuracy: 0.3015 - val_loss: 1.9479 - val_accuracy: 0.3194\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 997us/step - loss: 1.9381 - accuracy: 0.3110 - val_loss: 1.9424 - val_accuracy: 0.3177\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 992us/step - loss: 1.9100 - accuracy: 0.3209 - val_loss: 1.9339 - val_accuracy: 0.3196\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8976 - accuracy: 0.3248 - val_loss: 1.9386 - val_accuracy: 0.3228\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.8746 - accuracy: 0.3310 - val_loss: 1.9289 - val_accuracy: 0.3256\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8571 - accuracy: 0.3395 - val_loss: 1.9237 - val_accuracy: 0.3230\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8489 - accuracy: 0.3396 - val_loss: 1.9185 - val_accuracy: 0.3239\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8355 - accuracy: 0.3413 - val_loss: 1.9206 - val_accuracy: 0.3293\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8088 - accuracy: 0.3483 - val_loss: 1.9205 - val_accuracy: 0.3205\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7979 - accuracy: 0.3565 - val_loss: 1.9231 - val_accuracy: 0.3211\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.7879 - accuracy: 0.3603 - val_loss: 1.9339 - val_accuracy: 0.3196\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7718 - accuracy: 0.3636 - val_loss: 1.9266 - val_accuracy: 0.3248\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9184615520459964\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 2.2940 - accuracy: 0.1804 - val_loss: 2.1463 - val_accuracy: 0.2372\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.1448 - accuracy: 0.2407 - val_loss: 2.0437 - val_accuracy: 0.2868\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 43s 2ms/step - loss: 2.0808 - accuracy: 0.2599 - val_loss: 2.0104 - val_accuracy: 0.2994\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 82s 4ms/step - loss: 2.0283 - accuracy: 0.2779 - val_loss: 1.9799 - val_accuracy: 0.3091\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.9957 - accuracy: 0.2906 - val_loss: 1.9697 - val_accuracy: 0.3093\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.9742 - accuracy: 0.2966 - val_loss: 1.9534 - val_accuracy: 0.3134\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9445 - accuracy: 0.3040 - val_loss: 1.9437 - val_accuracy: 0.3194\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9280 - accuracy: 0.3136 - val_loss: 1.9399 - val_accuracy: 0.3239\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9102 - accuracy: 0.3195 - val_loss: 1.9396 - val_accuracy: 0.3172\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 19s 999us/step - loss: 1.8943 - accuracy: 0.3199 - val_loss: 1.9309 - val_accuracy: 0.3228\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8720 - accuracy: 0.3317 - val_loss: 1.9297 - val_accuracy: 0.3213\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 19s 999us/step - loss: 1.8544 - accuracy: 0.3417 - val_loss: 1.9215 - val_accuracy: 0.3263\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8432 - accuracy: 0.3401 - val_loss: 1.9205 - val_accuracy: 0.3308\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8204 - accuracy: 0.3466 - val_loss: 1.9214 - val_accuracy: 0.3293\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 21s 1ms/step - loss: 1.8191 - accuracy: 0.3457 - val_loss: 1.9190 - val_accuracy: 0.3258\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.7993 - accuracy: 0.3514 - val_loss: 1.9215 - val_accuracy: 0.3329\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 969us/step - loss: 1.7910 - accuracy: 0.3556 - val_loss: 1.9204 - val_accuracy: 0.3293\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 1.7785 - accuracy: 0.3669 - val_loss: 1.9194 - val_accuracy: 0.3305\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 974us/step - loss: 1.7592 - accuracy: 0.3625 - val_loss: 1.9237 - val_accuracy: 0.3340\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 1.7468 - accuracy: 0.3732 - val_loss: 1.9259 - val_accuracy: 0.3301\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9189782272796585\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2967 - accuracy: 0.1823 - val_loss: 2.1264 - val_accuracy: 0.2486\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 2.1396 - accuracy: 0.2416 - val_loss: 2.0510 - val_accuracy: 0.2881\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 973us/step - loss: 2.0729 - accuracy: 0.2663 - val_loss: 2.0083 - val_accuracy: 0.2962\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.0220 - accuracy: 0.2796 - val_loss: 1.9812 - val_accuracy: 0.3048\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 2.0013 - accuracy: 0.2910 - val_loss: 1.9656 - val_accuracy: 0.3063\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.9741 - accuracy: 0.2988 - val_loss: 1.9579 - val_accuracy: 0.3087\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 1.9419 - accuracy: 0.3094 - val_loss: 1.9428 - val_accuracy: 0.3228\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.9191 - accuracy: 0.3152 - val_loss: 1.9359 - val_accuracy: 0.3172\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.8976 - accuracy: 0.3209 - val_loss: 1.9336 - val_accuracy: 0.3196\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.8840 - accuracy: 0.3256 - val_loss: 1.9237 - val_accuracy: 0.3200\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 977us/step - loss: 1.8638 - accuracy: 0.3323 - val_loss: 1.9192 - val_accuracy: 0.3241\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 977us/step - loss: 1.8484 - accuracy: 0.3368 - val_loss: 1.9149 - val_accuracy: 0.3271\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.8316 - accuracy: 0.3465 - val_loss: 1.9165 - val_accuracy: 0.3267\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8252 - accuracy: 0.3462 - val_loss: 1.9225 - val_accuracy: 0.3222\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.8107 - accuracy: 0.3510 - val_loss: 1.9183 - val_accuracy: 0.3235\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8002 - accuracy: 0.3557 - val_loss: 1.9208 - val_accuracy: 0.3166\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 1.7795 - accuracy: 0.3551 - val_loss: 1.9306 - val_accuracy: 0.3198\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9148624545929722\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2906 - accuracy: 0.1796 - val_loss: 2.1471 - val_accuracy: 0.2728\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 2.1287 - accuracy: 0.2429 - val_loss: 2.0346 - val_accuracy: 0.2812\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.0664 - accuracy: 0.2652 - val_loss: 2.0022 - val_accuracy: 0.3009\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 2.0302 - accuracy: 0.2808 - val_loss: 1.9979 - val_accuracy: 0.3009\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.9944 - accuracy: 0.2883 - val_loss: 1.9668 - val_accuracy: 0.3172\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.9729 - accuracy: 0.3006 - val_loss: 1.9519 - val_accuracy: 0.3162\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.9433 - accuracy: 0.3096 - val_loss: 1.9482 - val_accuracy: 0.3160\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9222 - accuracy: 0.3136 - val_loss: 1.9341 - val_accuracy: 0.3155\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.9001 - accuracy: 0.3181 - val_loss: 1.9377 - val_accuracy: 0.3220\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8834 - accuracy: 0.3287 - val_loss: 1.9291 - val_accuracy: 0.3248\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 1.8731 - accuracy: 0.3288 - val_loss: 1.9221 - val_accuracy: 0.3209\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8531 - accuracy: 0.3358 - val_loss: 1.9196 - val_accuracy: 0.3295\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8395 - accuracy: 0.3368 - val_loss: 1.9178 - val_accuracy: 0.3185\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.8337 - accuracy: 0.3443 - val_loss: 1.9200 - val_accuracy: 0.3243\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8106 - accuracy: 0.3484 - val_loss: 1.9244 - val_accuracy: 0.3168\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.8060 - accuracy: 0.3502 - val_loss: 1.9214 - val_accuracy: 0.3198\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.7758 - accuracy: 0.3594 - val_loss: 1.9167 - val_accuracy: 0.3271\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7783 - accuracy: 0.3571 - val_loss: 1.9183 - val_accuracy: 0.3228\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 18s 977us/step - loss: 1.7681 - accuracy: 0.3626 - val_loss: 1.9245 - val_accuracy: 0.3243\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 1.7450 - accuracy: 0.3664 - val_loss: 1.9242 - val_accuracy: 0.3198\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9242443343662827\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 997us/step - loss: 2.2919 - accuracy: 0.1805 - val_loss: 2.1308 - val_accuracy: 0.2707\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 2.1297 - accuracy: 0.2441 - val_loss: 2.0439 - val_accuracy: 0.2876\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 2.0623 - accuracy: 0.2685 - val_loss: 2.0010 - val_accuracy: 0.3014\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 972us/step - loss: 2.0244 - accuracy: 0.2825 - val_loss: 1.9785 - val_accuracy: 0.3102\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 975us/step - loss: 1.9912 - accuracy: 0.2874 - val_loss: 1.9633 - val_accuracy: 0.3190\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 970us/step - loss: 1.9629 - accuracy: 0.2992 - val_loss: 1.9474 - val_accuracy: 0.3252\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9364 - accuracy: 0.3113 - val_loss: 1.9367 - val_accuracy: 0.3175\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 976us/step - loss: 1.9199 - accuracy: 0.3141 - val_loss: 1.9312 - val_accuracy: 0.3224\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8919 - accuracy: 0.3251 - val_loss: 1.9252 - val_accuracy: 0.3209\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.8746 - accuracy: 0.3325 - val_loss: 1.9240 - val_accuracy: 0.3181\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 1.8584 - accuracy: 0.3338 - val_loss: 1.9240 - val_accuracy: 0.3226\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8500 - accuracy: 0.3338 - val_loss: 1.9214 - val_accuracy: 0.3230\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8407 - accuracy: 0.3386 - val_loss: 1.9197 - val_accuracy: 0.3175\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 1.8215 - accuracy: 0.3440 - val_loss: 1.9192 - val_accuracy: 0.3250\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.8080 - accuracy: 0.3574 - val_loss: 1.9188 - val_accuracy: 0.3252\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.7989 - accuracy: 0.3530 - val_loss: 1.9162 - val_accuracy: 0.3241\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 998us/step - loss: 1.7764 - accuracy: 0.3642 - val_loss: 1.9206 - val_accuracy: 0.3205\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.7676 - accuracy: 0.3624 - val_loss: 1.9184 - val_accuracy: 0.3235\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 19s 1000us/step - loss: 1.7514 - accuracy: 0.3694 - val_loss: 1.9252 - val_accuracy: 0.3220\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.7343 - accuracy: 0.3773 - val_loss: 1.9234 - val_accuracy: 0.3228\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9234279710715054\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.3018 - accuracy: 0.1767 - val_loss: 2.1418 - val_accuracy: 0.2317\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 2.1428 - accuracy: 0.2426 - val_loss: 2.0460 - val_accuracy: 0.2834\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.0675 - accuracy: 0.2694 - val_loss: 2.0065 - val_accuracy: 0.3091\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.0248 - accuracy: 0.2835 - val_loss: 1.9839 - val_accuracy: 0.3127\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.9896 - accuracy: 0.2897 - val_loss: 1.9668 - val_accuracy: 0.3110\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 992us/step - loss: 1.9615 - accuracy: 0.3033 - val_loss: 1.9471 - val_accuracy: 0.3211\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9367 - accuracy: 0.3106 - val_loss: 1.9406 - val_accuracy: 0.3198\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 995us/step - loss: 1.9179 - accuracy: 0.3123 - val_loss: 1.9335 - val_accuracy: 0.3213\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.8886 - accuracy: 0.3272 - val_loss: 1.9350 - val_accuracy: 0.3228\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.8815 - accuracy: 0.3279 - val_loss: 1.9297 - val_accuracy: 0.3207\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.8609 - accuracy: 0.3328 - val_loss: 1.9234 - val_accuracy: 0.3280\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.8413 - accuracy: 0.3424 - val_loss: 1.9240 - val_accuracy: 0.3286\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8272 - accuracy: 0.3445 - val_loss: 1.9194 - val_accuracy: 0.3252\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.8172 - accuracy: 0.3513 - val_loss: 1.9170 - val_accuracy: 0.3233\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.8032 - accuracy: 0.3537 - val_loss: 1.9201 - val_accuracy: 0.3215\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 1.7834 - accuracy: 0.3649 - val_loss: 1.9155 - val_accuracy: 0.3260\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 999us/step - loss: 1.7724 - accuracy: 0.3665 - val_loss: 1.9235 - val_accuracy: 0.3290\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 991us/step - loss: 1.7691 - accuracy: 0.3658 - val_loss: 1.9207 - val_accuracy: 0.3226\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.7502 - accuracy: 0.3704 - val_loss: 1.9283 - val_accuracy: 0.3267\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 1.7360 - accuracy: 0.3773 - val_loss: 1.9239 - val_accuracy: 0.3282\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.923883604546905\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2841 - accuracy: 0.1834 - val_loss: 2.1250 - val_accuracy: 0.2565\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 19s 992us/step - loss: 2.1326 - accuracy: 0.2470 - val_loss: 2.0389 - val_accuracy: 0.2776\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 2.0651 - accuracy: 0.2662 - val_loss: 1.9946 - val_accuracy: 0.2967\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 991us/step - loss: 2.0248 - accuracy: 0.2825 - val_loss: 1.9742 - val_accuracy: 0.3100\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.9918 - accuracy: 0.2922 - val_loss: 1.9614 - val_accuracy: 0.3151\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.9596 - accuracy: 0.3054 - val_loss: 1.9475 - val_accuracy: 0.3200\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9374 - accuracy: 0.3093 - val_loss: 1.9354 - val_accuracy: 0.3226\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.9140 - accuracy: 0.3158 - val_loss: 1.9318 - val_accuracy: 0.3170\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.8993 - accuracy: 0.3187 - val_loss: 1.9291 - val_accuracy: 0.3245\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.8785 - accuracy: 0.3332 - val_loss: 1.9219 - val_accuracy: 0.3252\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 18s 979us/step - loss: 1.8601 - accuracy: 0.3307 - val_loss: 1.9220 - val_accuracy: 0.3252\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 977us/step - loss: 1.8395 - accuracy: 0.3461 - val_loss: 1.9206 - val_accuracy: 0.3280\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 985us/step - loss: 1.8246 - accuracy: 0.3461 - val_loss: 1.9201 - val_accuracy: 0.3267\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 1.8159 - accuracy: 0.3479 - val_loss: 1.9211 - val_accuracy: 0.3273\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 978us/step - loss: 1.8026 - accuracy: 0.3486 - val_loss: 1.9184 - val_accuracy: 0.3265\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 1.7863 - accuracy: 0.3610 - val_loss: 1.9318 - val_accuracy: 0.3151\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.7779 - accuracy: 0.3663 - val_loss: 1.9243 - val_accuracy: 0.3226\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 19s 996us/step - loss: 1.7603 - accuracy: 0.3674 - val_loss: 1.9291 - val_accuracy: 0.3254\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 18s 982us/step - loss: 1.7511 - accuracy: 0.3724 - val_loss: 1.9256 - val_accuracy: 0.3228\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 1.7316 - accuracy: 0.3762 - val_loss: 1.9241 - val_accuracy: 0.3237\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9183757476811667\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2998 - accuracy: 0.1807 - val_loss: 2.1360 - val_accuracy: 0.2565\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 992us/step - loss: 2.1310 - accuracy: 0.2455 - val_loss: 2.0525 - val_accuracy: 0.2771\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 2.0641 - accuracy: 0.2743 - val_loss: 2.0147 - val_accuracy: 0.3001\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 2.0244 - accuracy: 0.2795 - val_loss: 1.9735 - val_accuracy: 0.3123\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 979us/step - loss: 1.9938 - accuracy: 0.2941 - val_loss: 1.9608 - val_accuracy: 0.3190\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 977us/step - loss: 1.9584 - accuracy: 0.3027 - val_loss: 1.9499 - val_accuracy: 0.3170\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 19s 997us/step - loss: 1.9371 - accuracy: 0.3081 - val_loss: 1.9369 - val_accuracy: 0.3205\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.9126 - accuracy: 0.3153 - val_loss: 1.9323 - val_accuracy: 0.3222\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 1.8968 - accuracy: 0.3242 - val_loss: 1.9273 - val_accuracy: 0.3237\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 980us/step - loss: 1.8786 - accuracy: 0.3288 - val_loss: 1.9277 - val_accuracy: 0.3230\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 981us/step - loss: 1.8630 - accuracy: 0.3313 - val_loss: 1.9199 - val_accuracy: 0.3267\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.8476 - accuracy: 0.3394 - val_loss: 1.9219 - val_accuracy: 0.3202\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.8331 - accuracy: 0.3479 - val_loss: 1.9314 - val_accuracy: 0.3179\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.8097 - accuracy: 0.3506 - val_loss: 1.9202 - val_accuracy: 0.3297\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 984us/step - loss: 1.7988 - accuracy: 0.3543 - val_loss: 1.9298 - val_accuracy: 0.3140\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.7907 - accuracy: 0.3560 - val_loss: 1.9263 - val_accuracy: 0.3183\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9199293187536948\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2867 - accuracy: 0.1850 - val_loss: 2.1577 - val_accuracy: 0.2572\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 18s 992us/step - loss: 2.1259 - accuracy: 0.2479 - val_loss: 2.0286 - val_accuracy: 0.2988\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 2.0618 - accuracy: 0.2694 - val_loss: 1.9998 - val_accuracy: 0.3076\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 2.0216 - accuracy: 0.2806 - val_loss: 1.9772 - val_accuracy: 0.3134\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.9904 - accuracy: 0.2924 - val_loss: 1.9643 - val_accuracy: 0.3145\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.9588 - accuracy: 0.3042 - val_loss: 1.9540 - val_accuracy: 0.3226\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.9399 - accuracy: 0.3123 - val_loss: 1.9441 - val_accuracy: 0.3250\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.9129 - accuracy: 0.3211 - val_loss: 1.9355 - val_accuracy: 0.3241\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 18s 986us/step - loss: 1.8939 - accuracy: 0.3232 - val_loss: 1.9351 - val_accuracy: 0.3185\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 18s 987us/step - loss: 1.8787 - accuracy: 0.3264 - val_loss: 1.9353 - val_accuracy: 0.3218\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 1.8665 - accuracy: 0.3346 - val_loss: 1.9275 - val_accuracy: 0.3192\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8537 - accuracy: 0.3401 - val_loss: 1.9261 - val_accuracy: 0.3237\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 991us/step - loss: 1.8436 - accuracy: 0.3375 - val_loss: 1.9236 - val_accuracy: 0.3297\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 18s 988us/step - loss: 1.8199 - accuracy: 0.3506 - val_loss: 1.9221 - val_accuracy: 0.3239\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 18s 992us/step - loss: 1.8055 - accuracy: 0.3575 - val_loss: 1.9220 - val_accuracy: 0.3230\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 1.7875 - accuracy: 0.3550 - val_loss: 1.9218 - val_accuracy: 0.3235\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 995us/step - loss: 1.7761 - accuracy: 0.3647 - val_loss: 1.9204 - val_accuracy: 0.3280\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 1.7658 - accuracy: 0.3650 - val_loss: 1.9204 - val_accuracy: 0.3243\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 19s 997us/step - loss: 1.7544 - accuracy: 0.3660 - val_loss: 1.9287 - val_accuracy: 0.3230\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 18s 989us/step - loss: 1.7384 - accuracy: 0.3748 - val_loss: 1.9332 - val_accuracy: 0.3209\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9331838647829562\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.2916 - accuracy: 0.1807 - val_loss: 2.1232 - val_accuracy: 0.2304\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.1341 - accuracy: 0.2462 - val_loss: 2.0523 - val_accuracy: 0.2872\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 18s 991us/step - loss: 2.0626 - accuracy: 0.2630 - val_loss: 2.0044 - val_accuracy: 0.3067\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 19s 996us/step - loss: 2.0179 - accuracy: 0.2843 - val_loss: 1.9740 - val_accuracy: 0.3175\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 19s 993us/step - loss: 1.9926 - accuracy: 0.3000 - val_loss: 1.9647 - val_accuracy: 0.3181\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.9607 - accuracy: 0.3031 - val_loss: 1.9704 - val_accuracy: 0.3097\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 18s 983us/step - loss: 1.9428 - accuracy: 0.3114 - val_loss: 1.9386 - val_accuracy: 0.3218\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 18s 990us/step - loss: 1.9208 - accuracy: 0.3166 - val_loss: 1.9365 - val_accuracy: 0.3177\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.9012 - accuracy: 0.3228 - val_loss: 1.9257 - val_accuracy: 0.3241\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 21s 1ms/step - loss: 1.8836 - accuracy: 0.3292 - val_loss: 1.9264 - val_accuracy: 0.3263\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 20s 1ms/step - loss: 1.8628 - accuracy: 0.3340 - val_loss: 1.9207 - val_accuracy: 0.3226\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8499 - accuracy: 0.3403 - val_loss: 1.9213 - val_accuracy: 0.3288\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8325 - accuracy: 0.3479 - val_loss: 1.9189 - val_accuracy: 0.3297\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.8259 - accuracy: 0.3468 - val_loss: 1.9198 - val_accuracy: 0.3282\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 19s 994us/step - loss: 1.8017 - accuracy: 0.3535 - val_loss: 1.9217 - val_accuracy: 0.3250\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7896 - accuracy: 0.3544 - val_loss: 1.9296 - val_accuracy: 0.3258\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7797 - accuracy: 0.3637 - val_loss: 1.9211 - val_accuracy: 0.3278\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 1.7676 - accuracy: 0.3701 - val_loss: 1.9211 - val_accuracy: 0.3275\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.91888251530631\n",
      "Average CV Loss of 20 Runs : 1.9206236411548605\n"
     ]
    }
   ],
   "source": [
    "model_list=NN(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9564), started 0:00:43 ago. (Use '!kill 9564' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26b30dec5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs_301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_avg=np.zeros((test_2.shape[0],12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_list)):\n",
    "    test_pred=model_list[i].predict_proba(test_2)\n",
    "    test_pred_avg+=test_pred\n",
    "test_pred_avg/=len(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Test Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import savez_compressed\n",
    "\n",
    "savez_compressed('model_nn_events.npz', test_pred_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Neural Network 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Architecture Refered from Competition 3rd Place Winner: https://github.com/chechir/talking_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in this Network the Dropout in the input Layer adds value and variability for predictions and is helpful for taking avaerage of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_nn_1(input_dim,output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.4, input_shape=(input_dim,)))\n",
    "    model.add(Dense(75))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.30))\n",
    "    model.add(Dense(50, init='normal', activation='tanh'))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.20))\n",
    "    model.add(Dense(output_dim, init='normal', activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_102 (Dropout)        (None, 21566)             0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 75)                1617525   \n",
      "_________________________________________________________________\n",
      "p_re_lu_76 (PReLU)           (None, 75)                75        \n",
      "_________________________________________________________________\n",
      "dropout_103 (Dropout)        (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 50)                3800      \n",
      "_________________________________________________________________\n",
      "p_re_lu_77 (PReLU)           (None, 50)                50        \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 12)                612       \n",
      "=================================================================\n",
      "Total params: 1,622,062\n",
      "Trainable params: 1,622,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_nn_1(X_tr_event_o_h.shape[1],12)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_1(n_models):\n",
    "\n",
    "    model_list_1=[]\n",
    "    avg_cv_loss=0\n",
    "    for i in range(n_models):\n",
    "        model=model_nn_1(train_2.shape[1],12)\n",
    "        logdir = os.path.join(\"logs_301\",\"Model_nn_1.\"+str(i+1))\n",
    "        t_callback=TensorBoard(log_dir=logdir)\n",
    "        model.fit(train_2, y_train_nn_3, batch_size=149, epochs=20, verbose=1, validation_data=(cv_2, y_cv_nn_3),callbacks=[early_stop_1,t_callback])\n",
    "        model_cv_prediction=model.predict_proba(cv_2)\n",
    "        cv_loss=log_loss(y_cv_2, model_cv_prediction)\n",
    "        print(\"CV Log Loss of Best Weights Model in Current Run: \",cv_loss)\n",
    "        model_list_1.append(model)\n",
    "        avg_cv_loss+=cv_loss\n",
    "    avg_cv_loss/=n_models\n",
    "    print(\"Average CV Loss of \"+str(n_models)+\" Runs :\",avg_cv_loss)\n",
    "    return model_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 16s 847us/step - loss: 2.3290 - accuracy: 0.1722 - val_loss: 2.2321 - val_accuracy: 0.2072\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 15s 796us/step - loss: 2.1519 - accuracy: 0.2397 - val_loss: 2.1386 - val_accuracy: 0.2432\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 15s 801us/step - loss: 2.0809 - accuracy: 0.2659 - val_loss: 2.0956 - val_accuracy: 0.2533\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 14s 765us/step - loss: 2.0379 - accuracy: 0.2826 - val_loss: 1.9841 - val_accuracy: 0.3072\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 15s 784us/step - loss: 2.0133 - accuracy: 0.2902 - val_loss: 1.9847 - val_accuracy: 0.3138\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 764us/step - loss: 1.9885 - accuracy: 0.2980 - val_loss: 1.9868 - val_accuracy: 0.3044\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 781us/step - loss: 1.9707 - accuracy: 0.3088 - val_loss: 1.9685 - val_accuracy: 0.3183\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 1.9514 - accuracy: 0.3081 - val_loss: 1.9587 - val_accuracy: 0.3153\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 781us/step - loss: 1.9366 - accuracy: 0.3115 - val_loss: 1.9276 - val_accuracy: 0.3314\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 15s 782us/step - loss: 1.9218 - accuracy: 0.3232 - val_loss: 1.9330 - val_accuracy: 0.3153\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 787us/step - loss: 1.9045 - accuracy: 0.3323 - val_loss: 1.9484 - val_accuracy: 0.3190\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 14s 770us/step - loss: 1.8929 - accuracy: 0.3329 - val_loss: 1.9637 - val_accuracy: 0.3194\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 780us/step - loss: 1.8777 - accuracy: 0.3373 - val_loss: 1.9396 - val_accuracy: 0.3185\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 15s 782us/step - loss: 1.8649 - accuracy: 0.3401 - val_loss: 1.9585 - val_accuracy: 0.3175\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9275634543756874\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 16s 842us/step - loss: 2.3268 - accuracy: 0.1768 - val_loss: 2.2349 - val_accuracy: 0.2229\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 15s 802us/step - loss: 2.1522 - accuracy: 0.2399 - val_loss: 2.0437 - val_accuracy: 0.2932\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 15s 824us/step - loss: 2.0759 - accuracy: 0.2667 - val_loss: 2.0605 - val_accuracy: 0.2829\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 2.0428 - accuracy: 0.2793 - val_loss: 1.9972 - val_accuracy: 0.3100\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 15s 787us/step - loss: 2.0164 - accuracy: 0.2886 - val_loss: 1.9898 - val_accuracy: 0.3052\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 772us/step - loss: 1.9951 - accuracy: 0.2995 - val_loss: 1.9458 - val_accuracy: 0.3168\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 790us/step - loss: 1.9736 - accuracy: 0.3050 - val_loss: 1.9534 - val_accuracy: 0.3138\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 14s 776us/step - loss: 1.9510 - accuracy: 0.3093 - val_loss: 1.9388 - val_accuracy: 0.3179\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 804us/step - loss: 1.9399 - accuracy: 0.3157 - val_loss: 1.9469 - val_accuracy: 0.3218\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 14s 775us/step - loss: 1.9280 - accuracy: 0.3161 - val_loss: 1.9411 - val_accuracy: 0.3228\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 786us/step - loss: 1.9113 - accuracy: 0.3256 - val_loss: 1.9569 - val_accuracy: 0.3125\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 15s 787us/step - loss: 1.8896 - accuracy: 0.3330 - val_loss: 1.9378 - val_accuracy: 0.3183\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 796us/step - loss: 1.8717 - accuracy: 0.3356 - val_loss: 1.9424 - val_accuracy: 0.3235\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 14s 773us/step - loss: 1.8633 - accuracy: 0.3391 - val_loss: 1.9310 - val_accuracy: 0.3284\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 15s 786us/step - loss: 1.8543 - accuracy: 0.3423 - val_loss: 1.9204 - val_accuracy: 0.3250\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 15s 780us/step - loss: 1.8447 - accuracy: 0.3478 - val_loss: 1.9471 - val_accuracy: 0.3155\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 15s 788us/step - loss: 1.8239 - accuracy: 0.3542 - val_loss: 1.9730 - val_accuracy: 0.3059\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 14s 771us/step - loss: 1.8111 - accuracy: 0.3560 - val_loss: 1.9317 - val_accuracy: 0.3256\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 15s 813us/step - loss: 1.7938 - accuracy: 0.3694 - val_loss: 1.9383 - val_accuracy: 0.3254\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 17s 906us/step - loss: 1.7827 - accuracy: 0.3703 - val_loss: 1.9752 - val_accuracy: 0.3140\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9203889556572717\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 18s 971us/step - loss: 2.3243 - accuracy: 0.1723 - val_loss: 2.2517 - val_accuracy: 0.1967\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 17s 921us/step - loss: 2.1515 - accuracy: 0.2416 - val_loss: 2.0818 - val_accuracy: 0.3027\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 17s 915us/step - loss: 2.0880 - accuracy: 0.2629 - val_loss: 2.0629 - val_accuracy: 0.2778\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 17s 933us/step - loss: 2.0533 - accuracy: 0.2782 - val_loss: 2.0521 - val_accuracy: 0.2902\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 17s 905us/step - loss: 2.0173 - accuracy: 0.2884 - val_loss: 1.9980 - val_accuracy: 0.3037\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 15s 819us/step - loss: 1.9937 - accuracy: 0.2974 - val_loss: 1.9560 - val_accuracy: 0.3183\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 14s 771us/step - loss: 1.9705 - accuracy: 0.3046 - val_loss: 1.9790 - val_accuracy: 0.3007\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 15s 787us/step - loss: 1.9553 - accuracy: 0.3124 - val_loss: 1.9652 - val_accuracy: 0.3140\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 14s 773us/step - loss: 1.9410 - accuracy: 0.3158 - val_loss: 1.9677 - val_accuracy: 0.3207\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 15s 794us/step - loss: 1.9258 - accuracy: 0.3192 - val_loss: 1.9300 - val_accuracy: 0.3250\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 779us/step - loss: 1.9167 - accuracy: 0.3235 - val_loss: 1.9354 - val_accuracy: 0.3211\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 15s 785us/step - loss: 1.8930 - accuracy: 0.3308 - val_loss: 1.9214 - val_accuracy: 0.3273\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 14s 771us/step - loss: 1.8803 - accuracy: 0.3378 - val_loss: 1.9300 - val_accuracy: 0.3224\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 15s 794us/step - loss: 1.8701 - accuracy: 0.3381 - val_loss: 1.9278 - val_accuracy: 0.3310\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 15s 781us/step - loss: 1.8510 - accuracy: 0.3468 - val_loss: 1.9447 - val_accuracy: 0.3224\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 15s 807us/step - loss: 1.8344 - accuracy: 0.3499 - val_loss: 1.9561 - val_accuracy: 0.3061\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 14s 771us/step - loss: 1.8213 - accuracy: 0.3571 - val_loss: 1.9250 - val_accuracy: 0.3218\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.921426031498797\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 16s 837us/step - loss: 2.3256 - accuracy: 0.1705 - val_loss: 2.2048 - val_accuracy: 0.2209\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 14s 766us/step - loss: 2.1608 - accuracy: 0.2403 - val_loss: 2.0683 - val_accuracy: 0.2673\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 15s 796us/step - loss: 2.0859 - accuracy: 0.2703 - val_loss: 2.0849 - val_accuracy: 0.2658\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 14s 766us/step - loss: 2.0484 - accuracy: 0.2781 - val_loss: 1.9908 - val_accuracy: 0.3067\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 15s 784us/step - loss: 2.0181 - accuracy: 0.2887 - val_loss: 2.0432 - val_accuracy: 0.2906\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 1.9932 - accuracy: 0.2994 - val_loss: 1.9655 - val_accuracy: 0.3157\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 804us/step - loss: 1.9748 - accuracy: 0.3035 - val_loss: 1.9478 - val_accuracy: 0.3130\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 1.9597 - accuracy: 0.3061 - val_loss: 1.9573 - val_accuracy: 0.3082\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 788us/step - loss: 1.9429 - accuracy: 0.3160 - val_loss: 1.9359 - val_accuracy: 0.3310\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 1.9224 - accuracy: 0.3209 - val_loss: 1.9377 - val_accuracy: 0.3151\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 798us/step - loss: 1.9154 - accuracy: 0.3272 - val_loss: 1.9353 - val_accuracy: 0.3196\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 14s 773us/step - loss: 1.8996 - accuracy: 0.3291 - val_loss: 1.9220 - val_accuracy: 0.3318\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 788us/step - loss: 1.8855 - accuracy: 0.3337 - val_loss: 1.9284 - val_accuracy: 0.3271\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 16s 879us/step - loss: 1.8704 - accuracy: 0.3388 - val_loss: 1.9210 - val_accuracy: 0.3218\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 16s 846us/step - loss: 1.8581 - accuracy: 0.3424 - val_loss: 1.9246 - val_accuracy: 0.3284\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 15s 790us/step - loss: 1.8433 - accuracy: 0.3477 - val_loss: 1.9169 - val_accuracy: 0.3366\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 15s 791us/step - loss: 1.8250 - accuracy: 0.3572 - val_loss: 1.9471 - val_accuracy: 0.3093\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 15s 780us/step - loss: 1.8162 - accuracy: 0.3545 - val_loss: 1.9304 - val_accuracy: 0.3237\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 15s 796us/step - loss: 1.8049 - accuracy: 0.3615 - val_loss: 1.9253 - val_accuracy: 0.3256\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 14s 774us/step - loss: 1.7888 - accuracy: 0.3675 - val_loss: 1.9610 - val_accuracy: 0.3147\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9610309245952628\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 16s 847us/step - loss: 2.3139 - accuracy: 0.1750 - val_loss: 2.2200 - val_accuracy: 0.2216\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 14s 777us/step - loss: 2.1504 - accuracy: 0.2411 - val_loss: 2.0829 - val_accuracy: 0.2765\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 15s 806us/step - loss: 2.0845 - accuracy: 0.2678 - val_loss: 2.0366 - val_accuracy: 0.2819\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 15s 789us/step - loss: 2.0413 - accuracy: 0.2821 - val_loss: 1.9865 - val_accuracy: 0.2986\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 15s 800us/step - loss: 2.0073 - accuracy: 0.2895 - val_loss: 2.0059 - val_accuracy: 0.3024\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 778us/step - loss: 1.9877 - accuracy: 0.2963 - val_loss: 1.9822 - val_accuracy: 0.2969\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 801us/step - loss: 1.9743 - accuracy: 0.3029 - val_loss: 1.9948 - val_accuracy: 0.2902\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 15s 779us/step - loss: 1.9514 - accuracy: 0.3161 - val_loss: 1.9297 - val_accuracy: 0.3211\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 804us/step - loss: 1.9364 - accuracy: 0.3165 - val_loss: 1.9432 - val_accuracy: 0.3218\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 15s 782us/step - loss: 1.9165 - accuracy: 0.3233 - val_loss: 1.9351 - val_accuracy: 0.3215\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 793us/step - loss: 1.9021 - accuracy: 0.3280 - val_loss: 1.9692 - val_accuracy: 0.3117\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 14s 775us/step - loss: 1.8901 - accuracy: 0.3343 - val_loss: 1.9295 - val_accuracy: 0.3254\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 797us/step - loss: 1.8675 - accuracy: 0.3430 - val_loss: 1.9380 - val_accuracy: 0.3211\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 14s 776us/step - loss: 1.8629 - accuracy: 0.3408 - val_loss: 1.9210 - val_accuracy: 0.3245\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 15s 793us/step - loss: 1.8494 - accuracy: 0.3458 - val_loss: 1.9381 - val_accuracy: 0.3172\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 15s 797us/step - loss: 1.8334 - accuracy: 0.3488 - val_loss: 1.9790 - val_accuracy: 0.3018\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 15s 809us/step - loss: 1.8231 - accuracy: 0.3557 - val_loss: 1.9892 - val_accuracy: 0.3059\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 15s 783us/step - loss: 1.8073 - accuracy: 0.3597 - val_loss: 1.9348 - val_accuracy: 0.3211\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 15s 791us/step - loss: 1.7895 - accuracy: 0.3652 - val_loss: 1.9315 - val_accuracy: 0.3237\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9209525147672697\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 15s 819us/step - loss: 2.3241 - accuracy: 0.1724 - val_loss: 2.1602 - val_accuracy: 0.2490\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 15s 825us/step - loss: 2.1553 - accuracy: 0.2412 - val_loss: 2.0938 - val_accuracy: 0.2664\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 15s 778us/step - loss: 2.0846 - accuracy: 0.2657 - val_loss: 2.0862 - val_accuracy: 0.2767\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 15s 799us/step - loss: 2.0507 - accuracy: 0.2787 - val_loss: 1.9916 - val_accuracy: 0.2979\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 15s 790us/step - loss: 2.0174 - accuracy: 0.2902 - val_loss: 1.9823 - val_accuracy: 0.3089\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 16s 845us/step - loss: 1.9918 - accuracy: 0.2944 - val_loss: 1.9562 - val_accuracy: 0.3215\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 781us/step - loss: 1.9791 - accuracy: 0.3015 - val_loss: 1.9648 - val_accuracy: 0.3057\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 15s 801us/step - loss: 1.9510 - accuracy: 0.3119 - val_loss: 1.9380 - val_accuracy: 0.3155\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 779us/step - loss: 1.9432 - accuracy: 0.3145 - val_loss: 1.9481 - val_accuracy: 0.3097\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 15s 805us/step - loss: 1.9255 - accuracy: 0.3137 - val_loss: 1.9356 - val_accuracy: 0.3151\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 15s 780us/step - loss: 1.9061 - accuracy: 0.3321 - val_loss: 1.9305 - val_accuracy: 0.3258\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 15s 798us/step - loss: 1.8983 - accuracy: 0.3340 - val_loss: 1.9396 - val_accuracy: 0.3230\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 783us/step - loss: 1.8815 - accuracy: 0.3321 - val_loss: 1.9403 - val_accuracy: 0.3209\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 15s 809us/step - loss: 1.8748 - accuracy: 0.3372 - val_loss: 1.9287 - val_accuracy: 0.3196\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 15s 780us/step - loss: 1.8573 - accuracy: 0.3445 - val_loss: 1.9230 - val_accuracy: 0.3243\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18647/18647 [==============================] - 15s 790us/step - loss: 1.8414 - accuracy: 0.3502 - val_loss: 1.9237 - val_accuracy: 0.3260\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 14s 774us/step - loss: 1.8267 - accuracy: 0.3544 - val_loss: 1.9390 - val_accuracy: 0.3222\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 15s 795us/step - loss: 1.8210 - accuracy: 0.3551 - val_loss: 1.9783 - val_accuracy: 0.3125\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 14s 776us/step - loss: 1.8057 - accuracy: 0.3662 - val_loss: 1.9259 - val_accuracy: 0.3215\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 15s 789us/step - loss: 1.7826 - accuracy: 0.3708 - val_loss: 1.9245 - val_accuracy: 0.3211\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9230055772599133\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 15s 805us/step - loss: 2.3235 - accuracy: 0.1720 - val_loss: 2.2472 - val_accuracy: 0.2164\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 16s 840us/step - loss: 2.1530 - accuracy: 0.2434 - val_loss: 2.0944 - val_accuracy: 0.2718\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 2.0807 - accuracy: 0.2663 - val_loss: 2.0319 - val_accuracy: 0.2834\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 15s 786us/step - loss: 2.0446 - accuracy: 0.2812 - val_loss: 2.0526 - val_accuracy: 0.2812\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 2.0137 - accuracy: 0.2886 - val_loss: 1.9886 - val_accuracy: 0.3119\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 15s 784us/step - loss: 1.9878 - accuracy: 0.3013 - val_loss: 1.9468 - val_accuracy: 0.3157\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 1.9672 - accuracy: 0.3033 - val_loss: 1.9350 - val_accuracy: 0.3187\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 15s 785us/step - loss: 1.9495 - accuracy: 0.3118 - val_loss: 1.9351 - val_accuracy: 0.3200\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 14s 773us/step - loss: 1.9303 - accuracy: 0.3162 - val_loss: 1.9326 - val_accuracy: 0.3237\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 15s 793us/step - loss: 1.9178 - accuracy: 0.3225 - val_loss: 1.9438 - val_accuracy: 0.3241\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 14s 775us/step - loss: 1.9079 - accuracy: 0.3290 - val_loss: 1.9561 - val_accuracy: 0.3177\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 15s 823us/step - loss: 1.8896 - accuracy: 0.3325 - val_loss: 1.9524 - val_accuracy: 0.3222\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 811us/step - loss: 1.8775 - accuracy: 0.3356 - val_loss: 1.9385 - val_accuracy: 0.3233\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 15s 813us/step - loss: 1.8628 - accuracy: 0.3396 - val_loss: 1.9570 - val_accuracy: 0.3205\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.932578403970961\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 17s 893us/step - loss: 2.3161 - accuracy: 0.1759 - val_loss: 2.1579 - val_accuracy: 0.2512\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 16s 854us/step - loss: 2.1515 - accuracy: 0.2437 - val_loss: 2.1334 - val_accuracy: 0.2512\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 19s 1ms/step - loss: 2.0818 - accuracy: 0.2648 - val_loss: 2.0126 - val_accuracy: 0.2825\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 15s 800us/step - loss: 2.0351 - accuracy: 0.2839 - val_loss: 1.9776 - val_accuracy: 0.3125\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 18s 949us/step - loss: 2.0152 - accuracy: 0.2893 - val_loss: 1.9669 - val_accuracy: 0.3136\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 751us/step - loss: 1.9904 - accuracy: 0.2989 - val_loss: 1.9631 - val_accuracy: 0.3205\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 14s 766us/step - loss: 1.9708 - accuracy: 0.3087 - val_loss: 1.9476 - val_accuracy: 0.3200\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 15s 820us/step - loss: 1.9471 - accuracy: 0.3090 - val_loss: 1.9332 - val_accuracy: 0.3226\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 15s 794us/step - loss: 1.9348 - accuracy: 0.3139 - val_loss: 1.9196 - val_accuracy: 0.3265\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 14s 744us/step - loss: 1.9180 - accuracy: 0.3195 - val_loss: 1.9399 - val_accuracy: 0.3190\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 14s 756us/step - loss: 1.9050 - accuracy: 0.3256 - val_loss: 1.9418 - val_accuracy: 0.3157\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 15s 830us/step - loss: 1.8914 - accuracy: 0.3313 - val_loss: 1.9559 - val_accuracy: 0.3179\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 18s 942us/step - loss: 1.8780 - accuracy: 0.3355 - val_loss: 1.9395 - val_accuracy: 0.3147\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 14s 742us/step - loss: 1.8635 - accuracy: 0.3372 - val_loss: 1.9285 - val_accuracy: 0.3175\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.9195732221116022\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 15s 814us/step - loss: 2.3239 - accuracy: 0.1698 - val_loss: 2.2136 - val_accuracy: 0.2351\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 14s 743us/step - loss: 2.1537 - accuracy: 0.2457 - val_loss: 2.0826 - val_accuracy: 0.2653\n",
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 14s 775us/step - loss: 2.0835 - accuracy: 0.2664 - val_loss: 2.0097 - val_accuracy: 0.3022\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 14s 742us/step - loss: 2.0398 - accuracy: 0.2833 - val_loss: 2.0014 - val_accuracy: 0.2917\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 14s 757us/step - loss: 2.0159 - accuracy: 0.2891 - val_loss: 1.9615 - val_accuracy: 0.3091\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 741us/step - loss: 1.9926 - accuracy: 0.2979 - val_loss: 1.9710 - val_accuracy: 0.3089\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 14s 757us/step - loss: 1.9676 - accuracy: 0.3062 - val_loss: 1.9520 - val_accuracy: 0.3207\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 14s 745us/step - loss: 1.9540 - accuracy: 0.3093 - val_loss: 1.9287 - val_accuracy: 0.3239\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 14s 757us/step - loss: 1.9415 - accuracy: 0.3110 - val_loss: 1.9617 - val_accuracy: 0.3117\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 14s 741us/step - loss: 1.9269 - accuracy: 0.3185 - val_loss: 1.9587 - val_accuracy: 0.3168\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 14s 756us/step - loss: 1.9058 - accuracy: 0.3278 - val_loss: 1.9276 - val_accuracy: 0.3293\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 1.9002 - accuracy: 0.3271 - val_loss: 1.9212 - val_accuracy: 0.3280\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 14s 748us/step - loss: 1.8858 - accuracy: 0.3349 - val_loss: 1.9225 - val_accuracy: 0.3269\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 14s 759us/step - loss: 1.8680 - accuracy: 0.3384 - val_loss: 1.9353 - val_accuracy: 0.3198\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 14s 740us/step - loss: 1.8568 - accuracy: 0.3382 - val_loss: 1.9234 - val_accuracy: 0.3286\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 14s 769us/step - loss: 1.8446 - accuracy: 0.3455 - val_loss: 1.9422 - val_accuracy: 0.3282\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 14s 746us/step - loss: 1.8352 - accuracy: 0.3488 - val_loss: 1.9410 - val_accuracy: 0.3183\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.921216788050866\n",
      "Train on 18647 samples, validate on 4662 samples\n",
      "Epoch 1/20\n",
      "18647/18647 [==============================] - 15s 789us/step - loss: 2.3270 - accuracy: 0.1702 - val_loss: 2.1845 - val_accuracy: 0.2278\n",
      "Epoch 2/20\n",
      "18647/18647 [==============================] - 14s 764us/step - loss: 2.1531 - accuracy: 0.2383 - val_loss: 2.0612 - val_accuracy: 0.2703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "18647/18647 [==============================] - 14s 764us/step - loss: 2.0865 - accuracy: 0.2665 - val_loss: 2.0615 - val_accuracy: 0.2782\n",
      "Epoch 4/20\n",
      "18647/18647 [==============================] - 14s 752us/step - loss: 2.0436 - accuracy: 0.2777 - val_loss: 2.0459 - val_accuracy: 0.2780\n",
      "Epoch 5/20\n",
      "18647/18647 [==============================] - 14s 757us/step - loss: 2.0168 - accuracy: 0.2914 - val_loss: 1.9980 - val_accuracy: 0.3067\n",
      "Epoch 6/20\n",
      "18647/18647 [==============================] - 14s 745us/step - loss: 1.9881 - accuracy: 0.2975 - val_loss: 1.9503 - val_accuracy: 0.3207\n",
      "Epoch 7/20\n",
      "18647/18647 [==============================] - 15s 788us/step - loss: 1.9704 - accuracy: 0.3024 - val_loss: 1.9628 - val_accuracy: 0.3202\n",
      "Epoch 8/20\n",
      "18647/18647 [==============================] - 14s 746us/step - loss: 1.9501 - accuracy: 0.3098 - val_loss: 1.9662 - val_accuracy: 0.3074\n",
      "Epoch 9/20\n",
      "18647/18647 [==============================] - 14s 760us/step - loss: 1.9369 - accuracy: 0.3164 - val_loss: 1.9492 - val_accuracy: 0.3164\n",
      "Epoch 10/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 1.9210 - accuracy: 0.3239 - val_loss: 1.9275 - val_accuracy: 0.3235\n",
      "Epoch 11/20\n",
      "18647/18647 [==============================] - 14s 776us/step - loss: 1.9100 - accuracy: 0.3228 - val_loss: 1.9251 - val_accuracy: 0.3233\n",
      "Epoch 12/20\n",
      "18647/18647 [==============================] - 14s 762us/step - loss: 1.8964 - accuracy: 0.3350 - val_loss: 1.9501 - val_accuracy: 0.3130\n",
      "Epoch 13/20\n",
      "18647/18647 [==============================] - 15s 792us/step - loss: 1.8821 - accuracy: 0.3318 - val_loss: 1.9221 - val_accuracy: 0.3230\n",
      "Epoch 14/20\n",
      "18647/18647 [==============================] - 14s 743us/step - loss: 1.8707 - accuracy: 0.3383 - val_loss: 1.9800 - val_accuracy: 0.3136\n",
      "Epoch 15/20\n",
      "18647/18647 [==============================] - 14s 767us/step - loss: 1.8537 - accuracy: 0.3465 - val_loss: 1.9305 - val_accuracy: 0.3256\n",
      "Epoch 16/20\n",
      "18647/18647 [==============================] - 14s 744us/step - loss: 1.8464 - accuracy: 0.3439 - val_loss: 1.9238 - val_accuracy: 0.3314\n",
      "Epoch 17/20\n",
      "18647/18647 [==============================] - 14s 761us/step - loss: 1.8323 - accuracy: 0.3539 - val_loss: 1.9188 - val_accuracy: 0.3348\n",
      "Epoch 18/20\n",
      "18647/18647 [==============================] - 14s 744us/step - loss: 1.8168 - accuracy: 0.3593 - val_loss: 1.9363 - val_accuracy: 0.3271\n",
      "Epoch 19/20\n",
      "18647/18647 [==============================] - 14s 744us/step - loss: 1.8048 - accuracy: 0.3642 - val_loss: 1.9342 - val_accuracy: 0.3254\n",
      "Epoch 20/20\n",
      "18647/18647 [==============================] - 14s 774us/step - loss: 1.7933 - accuracy: 0.3665 - val_loss: 1.9446 - val_accuracy: 0.3147\n",
      "CV Log Loss of Best Weights Model in Current Run:  1.944571897401888\n",
      "Average CV Loss of 10 Runs : 1.9292307769689518\n"
     ]
    }
   ],
   "source": [
    "model_list_1=NN_1(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9564), started 1:36:39 ago. (Use '!kill 9564' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x26b5861ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs_301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Test Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_avg_1=np.zeros((test_2.shape[0],12))\n",
    "for i in range(len(model_list_1)):\n",
    "    test_pred=model_list_1[i].predict_proba(test_2)\n",
    "    test_pred_avg_1+=test_pred\n",
    "test_pred_avg_1/=len(model_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving Test Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "savez_compressed('model_nn_1_events.npz', test_pred_avg_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Esembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach**\n",
    "1. **Devices with No Events Data:** Take Weighted Average of Predictions of Predictions of 3 Models:\n",
    "   * No Events Neural Network 1 Avearge Predictions (0.8)\n",
    "   * catbooster classifier Predictions (0.2)\n",
    "2. **Devices with Events Data:** Take Weighted Avearge of Predictions of 2 Models:\n",
    "   * Events Neural Network 1 Avearge Predictions (0.5)\n",
    "   * Events Neural Network 2 Avearge Predictions (0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Data Ensemble Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No Events Devices Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_1=0.8\n",
    "w1_2=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Prediction_1=(w1_1*test_pred_avg_nn)+(w1_2*test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Events Devices Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2_1=0.5\n",
    "w2_2=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Prediction_2=(w2_1*test_pred_avg)+(w2_2*test_pred_avg_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combing Events and No Events Devices Data for Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('gender_age_train.csv',index_col = 'device_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetencoder = LabelEncoder().fit(train.group)\n",
    "y = targetencoder.transform(train.group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F23-', 'F24-26', 'F27-28', 'F29-32', 'F33-42', 'F43+', 'M22-',\n",
       "       'M23-26', 'M27-28', 'M29-31', 'M32-38', 'M39+'], dtype=object)"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetencoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F23-</th>\n",
       "      <th>F24-26</th>\n",
       "      <th>F27-28</th>\n",
       "      <th>F29-32</th>\n",
       "      <th>F33-42</th>\n",
       "      <th>F43+</th>\n",
       "      <th>M22-</th>\n",
       "      <th>M23-26</th>\n",
       "      <th>M27-28</th>\n",
       "      <th>M29-31</th>\n",
       "      <th>M32-38</th>\n",
       "      <th>M39+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-5893464122623104785</th>\n",
       "      <td>0.046516</td>\n",
       "      <td>0.060896</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.046482</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>0.135927</td>\n",
       "      <td>0.099928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7560708697029818408</th>\n",
       "      <td>0.046516</td>\n",
       "      <td>0.060896</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>0.066214</td>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.046482</td>\n",
       "      <td>0.085103</td>\n",
       "      <td>0.160770</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.106067</td>\n",
       "      <td>0.135927</td>\n",
       "      <td>0.099928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289797889702373958</th>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.055849</td>\n",
       "      <td>0.043126</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>0.085016</td>\n",
       "      <td>0.065652</td>\n",
       "      <td>0.092377</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.116077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-402874006399730161</th>\n",
       "      <td>0.060095</td>\n",
       "      <td>0.055849</td>\n",
       "      <td>0.043126</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>0.085016</td>\n",
       "      <td>0.065652</td>\n",
       "      <td>0.092377</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.097663</td>\n",
       "      <td>0.125731</td>\n",
       "      <td>0.116077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751283639860028129</th>\n",
       "      <td>0.051586</td>\n",
       "      <td>0.060118</td>\n",
       "      <td>0.043177</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>0.084608</td>\n",
       "      <td>0.063743</td>\n",
       "      <td>0.075872</td>\n",
       "      <td>0.127347</td>\n",
       "      <td>0.075911</td>\n",
       "      <td>0.099634</td>\n",
       "      <td>0.141538</td>\n",
       "      <td>0.110047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F23-    F24-26    F27-28    F29-32    F33-42  \\\n",
       "device_id                                                                \n",
       "-5893464122623104785  0.046516  0.060896  0.042178  0.066214  0.058772   \n",
       "-7560708697029818408  0.046516  0.060896  0.042178  0.066214  0.058772   \n",
       " 289797889702373958   0.060095  0.055849  0.043126  0.068755  0.085016   \n",
       "-402874006399730161   0.060095  0.055849  0.043126  0.068755  0.085016   \n",
       " 5751283639860028129  0.051586  0.060118  0.043177  0.066417  0.084608   \n",
       "\n",
       "                          F43+      M22-    M23-26    M27-28    M29-31  \\\n",
       "device_id                                                                \n",
       "-5893464122623104785  0.046482  0.085103  0.160770  0.091149  0.106067   \n",
       "-7560708697029818408  0.046482  0.085103  0.160770  0.091149  0.106067   \n",
       " 289797889702373958   0.065652  0.092377  0.117560  0.072100  0.097663   \n",
       "-402874006399730161   0.065652  0.092377  0.117560  0.072100  0.097663   \n",
       " 5751283639860028129  0.063743  0.075872  0.127347  0.075911  0.099634   \n",
       "\n",
       "                        M32-38      M39+  \n",
       "device_id                                 \n",
       "-5893464122623104785  0.135927  0.099928  \n",
       "-7560708697029818408  0.135927  0.099928  \n",
       " 289797889702373958   0.125731  0.116077  \n",
       "-402874006399730161   0.125731  0.116077  \n",
       " 5751283639860028129  0.141538  0.110047  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_no_events = pd.DataFrame(Test_Prediction_1, index = test_no_events.index, columns=targetencoder.classes_)\n",
    "pred_no_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F23-</th>\n",
       "      <th>F24-26</th>\n",
       "      <th>F27-28</th>\n",
       "      <th>F29-32</th>\n",
       "      <th>F33-42</th>\n",
       "      <th>F43+</th>\n",
       "      <th>M22-</th>\n",
       "      <th>M23-26</th>\n",
       "      <th>M27-28</th>\n",
       "      <th>M29-31</th>\n",
       "      <th>M32-38</th>\n",
       "      <th>M39+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1002079943728939269</th>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.009580</td>\n",
       "      <td>0.041006</td>\n",
       "      <td>0.054165</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.025152</td>\n",
       "      <td>0.033059</td>\n",
       "      <td>0.101879</td>\n",
       "      <td>0.274758</td>\n",
       "      <td>0.452287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1547860181818787117</th>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.008162</td>\n",
       "      <td>0.013532</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.097445</td>\n",
       "      <td>0.092880</td>\n",
       "      <td>0.007399</td>\n",
       "      <td>0.040013</td>\n",
       "      <td>0.051221</td>\n",
       "      <td>0.118024</td>\n",
       "      <td>0.250005</td>\n",
       "      <td>0.281048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374582448058474277</th>\n",
       "      <td>0.018418</td>\n",
       "      <td>0.039339</td>\n",
       "      <td>0.052482</td>\n",
       "      <td>0.107382</td>\n",
       "      <td>0.154351</td>\n",
       "      <td>0.083599</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.051721</td>\n",
       "      <td>0.059779</td>\n",
       "      <td>0.107820</td>\n",
       "      <td>0.185560</td>\n",
       "      <td>0.123788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F23-    F24-26    F27-28    F29-32    F33-42  \\\n",
       "device_id                                                                \n",
       " 1002079943728939269  0.000494  0.001365  0.002690  0.009580  0.041006   \n",
       "-1547860181818787117  0.003196  0.008162  0.013532  0.037075  0.097445   \n",
       " 7374582448058474277  0.018418  0.039339  0.052482  0.107382  0.154351   \n",
       "\n",
       "                          F43+      M22-    M23-26    M27-28    M29-31  \\\n",
       "device_id                                                                \n",
       " 1002079943728939269  0.054165  0.003564  0.025152  0.033059  0.101879   \n",
       "-1547860181818787117  0.092880  0.007399  0.040013  0.051221  0.118024   \n",
       " 7374582448058474277  0.083599  0.015762  0.051721  0.059779  0.107820   \n",
       "\n",
       "                        M32-38      M39+  \n",
       "device_id                                 \n",
       " 1002079943728939269  0.274758  0.452287  \n",
       "-1547860181818787117  0.250005  0.281048  \n",
       " 7374582448058474277  0.185560  0.123788  "
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_events = pd.DataFrame(Test_Prediction_2, index = test_events.index, columns=targetencoder.classes_)\n",
    "pred_events.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.concat([pred_no_events,pred_events], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F23-</th>\n",
       "      <th>F24-26</th>\n",
       "      <th>F27-28</th>\n",
       "      <th>F29-32</th>\n",
       "      <th>F33-42</th>\n",
       "      <th>F43+</th>\n",
       "      <th>M22-</th>\n",
       "      <th>M23-26</th>\n",
       "      <th>M27-28</th>\n",
       "      <th>M29-31</th>\n",
       "      <th>M32-38</th>\n",
       "      <th>M39+</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-5893464122623104785</th>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>0.063468</td>\n",
       "      <td>0.060977</td>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.153906</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>0.110317</td>\n",
       "      <td>0.137851</td>\n",
       "      <td>0.103496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-7560708697029818408</th>\n",
       "      <td>0.045549</td>\n",
       "      <td>0.058701</td>\n",
       "      <td>0.041958</td>\n",
       "      <td>0.063468</td>\n",
       "      <td>0.060977</td>\n",
       "      <td>0.048448</td>\n",
       "      <td>0.085893</td>\n",
       "      <td>0.153906</td>\n",
       "      <td>0.089437</td>\n",
       "      <td>0.110317</td>\n",
       "      <td>0.137851</td>\n",
       "      <td>0.103496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289797889702373958</th>\n",
       "      <td>0.057273</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>0.066473</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>0.114932</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.128840</td>\n",
       "      <td>0.118041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-402874006399730161</th>\n",
       "      <td>0.057273</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.044172</td>\n",
       "      <td>0.068047</td>\n",
       "      <td>0.085202</td>\n",
       "      <td>0.066473</td>\n",
       "      <td>0.090492</td>\n",
       "      <td>0.114932</td>\n",
       "      <td>0.071593</td>\n",
       "      <td>0.098334</td>\n",
       "      <td>0.128840</td>\n",
       "      <td>0.118041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751283639860028129</th>\n",
       "      <td>0.050710</td>\n",
       "      <td>0.061175</td>\n",
       "      <td>0.042477</td>\n",
       "      <td>0.065752</td>\n",
       "      <td>0.086048</td>\n",
       "      <td>0.065553</td>\n",
       "      <td>0.075311</td>\n",
       "      <td>0.127792</td>\n",
       "      <td>0.076010</td>\n",
       "      <td>0.100656</td>\n",
       "      <td>0.139080</td>\n",
       "      <td>0.109436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F23-    F24-26    F27-28    F29-32    F33-42  \\\n",
       "device_id                                                                \n",
       "-5893464122623104785  0.045549  0.058701  0.041958  0.063468  0.060977   \n",
       "-7560708697029818408  0.045549  0.058701  0.041958  0.063468  0.060977   \n",
       " 289797889702373958   0.057273  0.056600  0.044172  0.068047  0.085202   \n",
       "-402874006399730161   0.057273  0.056600  0.044172  0.068047  0.085202   \n",
       " 5751283639860028129  0.050710  0.061175  0.042477  0.065752  0.086048   \n",
       "\n",
       "                          F43+      M22-    M23-26    M27-28    M29-31  \\\n",
       "device_id                                                                \n",
       "-5893464122623104785  0.048448  0.085893  0.153906  0.089437  0.110317   \n",
       "-7560708697029818408  0.048448  0.085893  0.153906  0.089437  0.110317   \n",
       " 289797889702373958   0.066473  0.090492  0.114932  0.071593  0.098334   \n",
       "-402874006399730161   0.066473  0.090492  0.114932  0.071593  0.098334   \n",
       " 5751283639860028129  0.065553  0.075311  0.127792  0.076010  0.100656   \n",
       "\n",
       "                        M32-38      M39+  \n",
       "device_id                                 \n",
       "-5893464122623104785  0.137851  0.103496  \n",
       "-7560708697029818408  0.137851  0.103496  \n",
       " 289797889702373958   0.128840  0.118041  \n",
       "-402874006399730161   0.128840  0.118041  \n",
       " 5751283639860028129  0.139080  0.109436  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('final_Submission.csv',index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
